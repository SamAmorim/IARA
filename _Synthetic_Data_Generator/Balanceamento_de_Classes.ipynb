{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16a0de88-e80e-49cd-a11d-e13f04122099",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Balanceamento de CLasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f4ad8d5-81e2-4d75-9e1f-8c3f2fbd2cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Analise de Classes Pré Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9701387f-33dd-4a93-af1e-7f0b728ef7c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "try:\n",
    "    # 1. Carrega a tabela original\n",
    "    df_original = spark.table(\"transacoes_db.copper.transacoes\")\n",
    "    \n",
    "    # 2. Calcula o total de registros\n",
    "    total_count = df_original.count()\n",
    "    \n",
    "    if total_count == 0:\n",
    "        print(\"AVISO: A tabela original está vazia. Nenhuma análise para mostrar.\")\n",
    "    else:\n",
    "        print(f\"Total de Registros (Original): {total_count}\\n\")\n",
    "        \n",
    "        # 3. Calcula a distribuição por 'is_fraud'\n",
    "        print(\"Distribuição por Classe (Original):\")\n",
    "        df_original.groupBy(\"is_fraud\") \\\n",
    "            .count() \\\n",
    "            .withColumn(\"percentual\", (F.col(\"count\") / total_count) * 100) \\\n",
    "            .orderBy(F.col(\"count\").desc()) \\\n",
    "            .show()\n",
    "\n",
    "        # 4. Calcula a distribuição detalhada por 'fraud_type'\n",
    "        print(\"Distribuição por Tipo de Fraude (Original):\")\n",
    "        df_original.withColumn(\n",
    "                \"tipo_fraude_detalhado\", \n",
    "                F.when(F.col(\"is_fraud\") == 0, \"Legitima\").otherwise(F.col(\"fraud_type\"))\n",
    "            ) \\\n",
    "            .groupBy(\"tipo_fraude_detalhado\") \\\n",
    "            .count() \\\n",
    "            .withColumn(\"percentual\", (F.col(\"count\") / total_count) * 100) \\\n",
    "            .orderBy(F.col(\"count\").desc()) \\\n",
    "            .show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERRO: Não foi possível ler 'transacoes_db.copper.transacoes'. Verifique se a Célula 3 foi executada.\")\n",
    "    print(f\"Detalhe: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bf39646-8586-41c4-a4a6-be396b952d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analise visual Pre Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f83eb37-c8dc-45e4-a97f-05c749f75dc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Carrega a tabela original\n",
    "df_original = spark.table(\"transacoes_db.copper.transacoes\")\n",
    "\n",
    "# 2. Calcula a distribuição por 'is_fraud'\n",
    "df_is_fraud = df_original.groupBy(\"is_fraud\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"is_fraud\")\n",
    "\n",
    "# 3. Calcula a distribuição detalhada por 'fraud_type'\n",
    "df_tipo_fraude = df_original.withColumn(\n",
    "        \"tipo_fraude_detalhado\", \n",
    "        F.when(F.col(\"is_fraud\") == 0, \"Legitima\").otherwise(F.col(\"fraud_type\"))\n",
    "    ) \\\n",
    "    .groupBy(\"tipo_fraude_detalhado\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.col(\"count\").desc())\n",
    "\n",
    "# Coleta os dados para visualização\n",
    "is_fraud_data = df_is_fraud.toPandas()\n",
    "tipo_fraude_data = df_tipo_fraude.toPandas()\n",
    "\n",
    "# Gráfico de barras para distribuição por classe\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(is_fraud_data['is_fraud'], is_fraud_data['count'], color=['green', 'red'])\n",
    "plt.xlabel('Classe (is_fraud)')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.title('Distribuição por Classe (Pré Balanceamento)')\n",
    "plt.xticks([0,1], ['Legitima', 'Fraude'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7b670e-c117-41ed-88c9-84f976792b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Gráfico de barras para distribuição por tipo de fraude\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(tipo_fraude_data['tipo_fraude_detalhado'], tipo_fraude_data['count'], color='orange')\n",
    "plt.xlabel('Tipo de Fraude')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.title('Distribuição por Tipo de Fraude (Pré Balanceamento)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1e58ce0-3e45-40ef-b35a-558fa630eddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Histograma dos valores transacionados por classe (Pré Balanceamento)\n",
    "valores_pd = df_original.select(\"is_fraud\", \"valor\").toPandas()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for label, color in zip([0,1], ['green', 'red']):\n",
    "    plt.hist(\n",
    "        valores_pd[valores_pd['is_fraud']==label]['valor'], \n",
    "        bins=30, \n",
    "        alpha=0.6, \n",
    "        label=f'{\"Legitima\" if label==0 else \"Fraude\"}', \n",
    "        color=color\n",
    "    )\n",
    "plt.title('Distribuição dos Valores Transacionados por Classe (Pré Balanceamento)')\n",
    "plt.xlabel('Valor da Transação')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c83837f3-44c4-438d-afa0-cee85adcdc3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Balanceamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04afd59a-15d2-439f-a400-8e6633a224fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"INFO: Iniciando processo de BALANCEAMENTO V11 (Robusto)...\")\n",
    "print(\"INFO: Classe 1 (Fraude) incluirá a Raiz E os Sintomas (filhos da cadeia).\")\n",
    "print(\"INFO: Classe 0 (Legítimo) incluirá APENAS transações legítimas.\")\n",
    "print(\"AVISO: Executando em modo 'SEM CACHE' por instrução. A execução pode ser lenta.\")\n",
    "\n",
    "# Usar a mesma seed global para reprodutibilidade\n",
    "SEED_BALANCEAMENTO = 42\n",
    "\n",
    "try:\n",
    "    df_transacoes = spark.table(\"transacoes_db.copper.transacoes\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASSO 1: Isolar as \"Fraudes\" (Classe 1 - Causa + Sintomas)\n",
    "    # =========================================================================\n",
    "    df_fraudes_all = df_transacoes.filter(\n",
    "        F.col(\"is_fraud\") == 1\n",
    "    ) # SEM .cache()\n",
    "    \n",
    "    count_fraudes_all = df_fraudes_all.count()\n",
    "\n",
    "    if count_fraudes_all == 0:\n",
    "        raise ValueError(\"ERRO CRÍTICO: Nenhuma transação com 'is_fraud = 1' foi encontrada.\")\n",
    "    \n",
    "    print(f\"INFO: Total de 'Fraudes' (Classe 1 - Original): {count_fraudes_all} linhas.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASSO 2: Isolar as \"Legítimas\" (Classe 0)\n",
    "    # =========================================================================\n",
    "    \n",
    "    df_legitimas_all = df_transacoes.filter(\n",
    "        F.col(\"is_fraud\") == 0\n",
    "    ) # SEM .cache()\n",
    "        \n",
    "    count_legitimas_all = df_legitimas_all.count()\n",
    "    \n",
    "    if count_legitimas_all == 0:\n",
    "        raise ValueError(\"ERRO CRÍTICO: Nenhuma transação com 'is_fraud = 0' foi encontrada.\")\n",
    "        \n",
    "    print(f\"INFO: Total de 'Legítimas' (Classe 0): {count_legitimas_all} linhas.\")\n",
    "\n",
    "    # =========================================================================\n",
    "    # PASSO 3: APLICAR OVERSAMPLING (Sobreamostragem) no bloco de 'Fraudes'\n",
    "    # =========================================================================\n",
    "    print(\"INFO: Iniciando Etapa 1: Oversampling Multiclasse (Balanceando tipos de fraude)...\")\n",
    "\n",
    "    # 3a. Encontrar a contagem da classe de fraude majoritária\n",
    "    df_counts = df_fraudes_all.groupBy(\"fraud_type\").count()\n",
    "    \n",
    "    # Coletar a contagem máxima para o driver\n",
    "    target_count_multiclass = df_counts.select(F.max(\"count\")).first()[0]\n",
    "    \n",
    "    print(f\"INFO: Classe de fraude majoritária tem {target_count_multiclass} amostras. Este é o alvo.\")\n",
    "    print(\"Distribuição de Fraudes (Antes do Oversampling):\")\n",
    "    df_counts.show()\n",
    "\n",
    "    # 3b. Calcular o fator de repetição para cada classe\n",
    "    df_fraudes_com_fator = df_fraudes_all.join(\n",
    "        df_counts.withColumn(\"target_count\", F.lit(target_count_multiclass)),\n",
    "        \"fraud_type\"\n",
    "    ).withColumn(\n",
    "        \"repeat_n\", \n",
    "        F.ceil(F.col(\"target_count\") / F.col(\"count\")).cast(\"int\") # Fator de repetição\n",
    "    )\n",
    "\n",
    "    # 3c. Explodir para duplicar as linhas das classes minoritárias\n",
    "    df_oversampled_base = df_fraudes_com_fator.withColumn(\n",
    "        \"copy_index\", \n",
    "        F.explode(F.sequence(F.lit(1), F.col(\"repeat_n\")))\n",
    "    )\n",
    "\n",
    "    # 3d. RE-GERAR IDs para evitar chaves duplicadas (APENAS PARA CÓPIAS)\n",
    "    df_fraudes_oversampled_com_novos_ids = df_oversampled_base.withColumn(\n",
    "        \"id_original\", F.col(\"id\") # Salva o ID original para referência\n",
    "    ).withColumn(\n",
    "        \"id\",\n",
    "        F.when(\n",
    "            F.col(\"copy_index\") > 1, F.expr(\"uuid()\") # Gera novo ID para cópias\n",
    "        ).otherwise(F.col(\"id\")) # Mantém o ID original\n",
    "    ).withColumn(\n",
    "        \"id_transacao_cadeia_pai\",\n",
    "        F.when(\n",
    "            F.col(\"copy_index\") > 1, F.lit(None) # Cópias não são \"filhas\"\n",
    "        ).otherwise(F.col(\"id_transacao_cadeia_pai\")) # Mantém o pai original\n",
    "    ).drop(\"count\", \"target_count\", \"repeat_n\", \"copy_index\", \"id_original\")\n",
    "    \n",
    "    \n",
    "    # 3e. Truncar (sample) de volta ao 'target_count'\n",
    "    window_spec = Window.partitionBy(\"fraud_type\").orderBy(F.rand(seed=SEED_BALANCEAMENTO))\n",
    "    \n",
    "    df_fraudes_balanceadas_multiclass = df_fraudes_oversampled_com_novos_ids \\\n",
    "        .withColumn(\"rank\", F.row_number().over(window_spec)) \\\n",
    "        .filter(F.col(\"rank\") <= target_count_multiclass) \\\n",
    "        .drop(\"rank\") # SEM .cache()\n",
    "\n",
    "    count_fraudes_balanceadas = df_fraudes_balanceadas_multiclass.count()\n",
    "    print(f\"INFO: Fraudes após oversampling (Etapa 1): {count_fraudes_balanceadas} linhas.\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # --- INÍCIO DA CORREÇÃO (PASSO 4 V11) ---\n",
    "    # PASSO 4: BALANCEAMENTO BINÁRIO ROBUSTO (Undersampling da Classe Majoritária)\n",
    "    # =========================================================================\n",
    "    print(\"INFO: Iniciando Etapa 2: Balanceamento Binário (Identificando a classe majoritária)...\")\n",
    "    \n",
    "    # count_fraudes_balanceadas (do PASSO 3)\n",
    "    # count_legitimas_all (do PASSO 2)\n",
    "\n",
    "    if count_fraudes_balanceadas == count_legitimas_all:\n",
    "        print(f\"INFO: Classes já estão balanceadas (1:1) com {count_fraudes_balanceadas} amostras cada. Nenhuma amostragem binária necessária.\")\n",
    "        df_fraudes_amostradas = df_fraudes_balanceadas_multiclass\n",
    "        df_legitimas_amostradas = df_legitimas_all\n",
    "    \n",
    "    elif count_fraudes_balanceadas > count_legitimas_all:\n",
    "        # CASO 1: Fraude é a MAIORIA (Aplicar Undersampling nas Fraudes)\n",
    "        # Isso acontece em datasets de baixa escala onde o oversampling de fraudes supera as legítimas.\n",
    "        print(f\"INFO: Classe 'Fraude' é a majoritária ({count_fraudes_balanceadas} vs {count_legitimas_all}).\")\n",
    "        print(\"INFO: Aplicando UNDERSAMPLING na classe 'Fraude'...\")\n",
    "        \n",
    "        fraction = count_legitimas_all / count_fraudes_balanceadas # (Será < 1.0)\n",
    "        print(f\"INFO: Fração de amostragem (Fraude): {fraction:.4f}\")\n",
    "        \n",
    "        df_fraudes_amostradas = df_fraudes_balanceadas_multiclass.sample(\n",
    "            withReplacement=False, \n",
    "            fraction=fraction, \n",
    "            seed=SEED_BALANCEAMENTO\n",
    "        )\n",
    "        df_legitimas_amostradas = df_legitimas_all # Manter todas as legítimas\n",
    "\n",
    "    else:\n",
    "        # CASO 2: Legítima é a MAIORIA (Aplicar Undersampling nas Legítimas)\n",
    "        # Este é o cenário esperado em produção.\n",
    "        print(f\"INFO: Classe 'Legítima' é a majoritária ({count_legitimas_all} vs {count_fraudes_balanceadas}).\")\n",
    "        print(\"INFO: Aplicando UNDERSAMPLING na classe 'Legítima'...\")\n",
    "        \n",
    "        fraction = count_fraudes_balanceadas / count_legitimas_all # (Será < 1.0)\n",
    "        print(f\"INFO: Fração de amostragem (Legítima): {fraction:.4f}\")\n",
    "        \n",
    "        df_legitimas_amostradas = df_legitimas_all.sample(\n",
    "            withReplacement=False, \n",
    "            fraction=fraction, \n",
    "            seed=SEED_BALANCEAMENTO\n",
    "        )\n",
    "        df_fraudes_amostradas = df_fraudes_balanceadas_multiclass # Manter todas as fraudes\n",
    "    \n",
    "\n",
    "\n",
    " \n",
    "    # PASSO 5: Unir e Salvar o Dataset Final\n",
    "\n",
    "    df_transacoes_balanced = df_fraudes_amostradas.unionByName(df_legitimas_amostradas)\n",
    "\n",
    "    print(\"INFO: Materializando dataset balanceado (V11-Robusto) como 'transacoes_db.gold.transacoes_balanced_model'...\")\n",
    "    spark.sql(\"CREATE SCHEMA IF NOT EXISTS transacoes_db.gold\")\n",
    "    \n",
    "    df_transacoes_balanced.write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"delta\") \\\n",
    "        .saveAsTable(\"transacoes_db.gold.transacoes_balanced_model\")\n",
    "    \n",
    "    print(\"✅ SUCESSO: Dataset balanceado (V11-Robusto) salvo.\")\n",
    "\n",
    "finally:\n",
    "    # Bloco 'finally' agora está seguro e não tenta limpar caches\n",
    "    print(\"INFO: Processo finalizado (sem caches para limpar).\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CÉLULA 6 (Verificação) - Execute esta após a Célula 5\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\\n--- VERIFICAÇÃO PÓS-BALANCEAMENTO (V11-ROBUSTO) ---\")\n",
    "df_check = spark.table(\"transacoes_db.gold.transacoes_balanced_model\")\n",
    "\n",
    "\n",
    "total_count_balanced = df_check.count()\n",
    "print(f\"Total de Registros (Balanceado): {total_count_balanced}\")\n",
    "\n",
    "print(\"\\nDistribuição por Classe (Balanceado):\")\n",
    "df_check.groupBy(\"is_fraud\").count().show()\n",
    "# Esperado: 50/50 (ou muito próximo)\n",
    "\n",
    "print(\"\\nDistribuição por Tipo de Fraude (Balanceado):\")\n",
    "df_check.withColumn(\n",
    "        \"tipo_fraude_detalhado\", \n",
    "        F.when(F.col(\"is_fraud\") == 0, \"Legitima\").otherwise(F.col(\"fraud_type\"))\n",
    "    ) \\\n",
    "    .groupBy(\"tipo_fraude_detalhado\") \\\n",
    "    .count() \\\n",
    "    .orderBy(F.col(\"count\").desc()) \\\n",
    "    .show()\n",
    "# Esperado: 'Legitima' (50%) e todos os tipos de fraude\n",
    "# (ex: 'valor_atipico', 'eng_social', etc.) com contagens IDÊNTICAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bfd390a-1b91-4ee1-a566-efdbda595e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analise visual Pos Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bb5bdfa-607f-45aa-8f26-dbb0962c238d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregar dados balanceados\n",
    "df_check = spark.table(\"transacoes_db.gold.transacoes_balanced_model\")\n",
    "\n",
    "# Coletar distribuição por classe\n",
    "dist_classe = df_check.groupBy(\"is_fraud\").count().orderBy(\"is_fraud\")\n",
    "classe_pd = dist_classe.toPandas()\n",
    "\n",
    "# Gráfico de barras: Distribuição por Classe\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(classe_pd['is_fraud'], classe_pd['count'], color=['#2ca02c', '#d62728'])\n",
    "plt.xticks([0,1], ['Legítima', 'Fraude'])\n",
    "plt.title('Distribuição por Classe (Balanceado)')\n",
    "plt.xlabel('Classe')\n",
    "plt.ylabel('Contagem')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cec8c767-59f9-4bd5-8577-703850a63658",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Coletar distribuição por tipo de fraude\n",
    "df_tipo = df_check.withColumn(\n",
    "    \"tipo_fraude_detalhado\", \n",
    "    F.when(F.col(\"is_fraud\") == 0, \"Legitima\").otherwise(F.col(\"fraud_type\"))\n",
    ").groupBy(\"tipo_fraude_detalhado\").count().orderBy(F.col(\"count\").desc())\n",
    "tipo_pd = df_tipo.toPandas()\n",
    "\n",
    "# Gráfico de barras: Distribuição por Tipo de Fraude\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(tipo_pd['tipo_fraude_detalhado'], tipo_pd['count'], color='#1f77b4')\n",
    "plt.title('Distribuição por Tipo de Fraude (Balanceado)')\n",
    "plt.xlabel('Tipo de Fraude')\n",
    "plt.ylabel('Contagem')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ec00de-c0b4-43ca-b3cb-1c5976ba0bb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Histograma de valores transacionados por classe (Pós Balanceamento)\n",
    "valores_pd = df_check.select(\n",
    "    \"is_fraud\", \n",
    "    \"valor\"\n",
    ").toPandas()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for label, color in zip([0,1], ['#2ca02c', '#d62728']):\n",
    "    plt.hist(\n",
    "        valores_pd[valores_pd['is_fraud']==label]['valor'], \n",
    "        bins=30, \n",
    "        alpha=0.6, \n",
    "        label=f'{\"Legítima\" if label==0 else \"Fraude\"}', \n",
    "        color=color\n",
    "    )\n",
    "plt.title('Distribuição dos Valores Transacionados por Classe (Pós Balanceamento)')\n",
    "plt.xlabel('Valor da Transação')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Balanceamento_de_Classes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
