{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18d0ce98-7b47-438d-8b5b-ef80c27a8879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.4.2 tensorflow==2.16.1 scikeras==0.13.0 joblib\n",
    "\n",
    "print(\"Dependências de MLOps instaladas/verificadas.\")\n",
    "print(\"Versões compatíveis: scikit-learn==1.4.2, tensorflow==2.16.1, scikeras==0.13.0\")\n",
    "print(\"Reiniciando o kernel Python agora para carregar as novas bibliotecas...\")\n",
    "\n",
    "\n",
    "# Esta função nativa do Databricks reinicia o kernel Python.\n",
    "# Todas as variáveis serão limpas, o que é o comportamento esperado \n",
    "# ao instalar bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e4b680-1fa5-49b6-82c4-2048826e8894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a3a7d3-5a0a-4818-a6fc-f0870a94cf8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from mlflow.models.signature import infer_signature\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configurações Globais ---\n",
    "# A View de features que já existe e será lida\n",
    "VIEW_NAME = \"transacoes_db.feature_store.in_live_features\"\n",
    "\n",
    "# --- MUDANÇA PRINCIPAL AQUI ---\n",
    "# Diretório em seu Volume do Unity Catalog para salvar os artefatos\n",
    "# (Assumindo que você queira manter uma subpasta 'pix_fraud' dentro do volume)\n",
    "MODEL_ARTIFACTS_DIR = \"/Volumes/transacoes_db/copper/files/pix_fraud/production_artifacts/\"\n",
    "# --- FIM DA MUDANÇA ---\n",
    "\n",
    "# Semente para reprodutibilidade\n",
    "SEED = 42\n",
    "\n",
    "# --- Configurações de Ambiente ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Garantir que o diretório de artefatos exista no Volume\n",
    "os.makedirs(MODEL_ARTIFACTS_DIR, exist_ok=True)\n",
    "print(f\"Diretório de artefatos garantido: {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "# --- Sementes de Aleatoriedade ---\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Inicializar SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84d8574-7052-4089-9393-ea6ee4d55c09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* CONTEXTO DA VIEW: transacoes_db.feature_store.in_live_features\n",
    "(Esta célula %sql é apenas para documentação, a view já existe)\n",
    "\n",
    "Esta view agrega dados transacionais com perfis e features de janela temporal.\n",
    "*\n",
    "SELECT\n",
    "  -- Colunas da transação\n",
    "  ft.valor AS valor_transacao,\n",
    "  ft.data AS data_transacao,\n",
    "  ft.id_conta_origem AS id_conta_pagador,\n",
    "  ft.id_conta_destino AS id_conta_recebedor,\n",
    "  ft.id_tipo_iniciacao_pix AS tipo_iniciacao_pix_id,\n",
    "  ft.id_finalidade_pix AS finalidade_pix_id,\n",
    "  \n",
    "  -- Targets (Rótulos)\n",
    "  ft.is_fraud AS transacao_fraudulenta, -- (Binário: 0 ou 1)\n",
    "  ft.fraud_type AS tipo_fraude,         -- (Multiclasse: 'scam', 'roubo', etc.)\n",
    "\n",
    "  -- Perfis (Pagador e Recebedor)\n",
    "  conta_orig.saldo AS pagador_saldo,\n",
    "  conta_orig.aberta_em AS pagador_conta_aberta_em,\n",
    "  conta_orig.id_tipo_conta AS pagador_tipo_conta_id,\n",
    "  cliente_orig.id_natureza AS pagador_natureza_id,\n",
    "  cliente_orig.nascido_em AS pagador_data_nascimento,\n",
    "  conta_dest.saldo AS recebedor_saldo,\n",
    "  conta_dest.aberta_em AS recebedor_conta_aberta_em,\n",
    "  conta_dest.id_tipo_conta AS recebedor_tipo_conta_id,\n",
    "  cliente_dest.id_natureza AS recebedor_natureza_id,\n",
    "  cliente_dest.nascido_em AS recebedor_data_nascimento,\n",
    "\n",
    "  -- Features de Tempo Real (Window Functions)\n",
    "  ft.pagador_txs_ultimas_24h,\n",
    "  ft.pagador_valor_ultimas_24h,\n",
    "  ft.recebedor_txs_ultima_1h,\n",
    "  ft.recebedor_valor_ultima_1h,\n",
    "  ft.pagador_segundos_desde_ultima_tx\n",
    "FROM\n",
    "  transacoes_db.feature_store.in_live_features AS ft\n",
    "... (JOINS com tabelas copper de perfis) ...\n",
    "limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651ce2fe-40e6-4f04-8086-3e583b471ac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Carregando dados da view: {VIEW_NAME}...\")\n",
    "# 1. Carregar dados do Delta Lake (Spark)\n",
    "df_spark = spark.read.table(VIEW_NAME)\n",
    "\n",
    "# 2. Converter para Pandas\n",
    "# Assumindo que o dataset cabe na memória do driver para treinamento com Sklearn/Keras\n",
    "df_pandas = df_spark.toPandas()\n",
    "print(f\"Dados carregados. Total de {len(df_pandas)} registros.\")\n",
    "\n",
    "# 3. Separar Features (X) e Targets (y)\n",
    "# IDs não são features para o modelo\n",
    "features_to_drop = ['transacao_fraudulenta', 'tipo_fraude', 'id_conta_pagador', 'id_conta_recebedor']\n",
    "X = df_pandas.drop(columns=features_to_drop)\n",
    "y_binary = df_pandas['transacao_fraudulenta']\n",
    "y_multiclass = df_pandas['tipo_fraude'] # Este ainda é string ('scam', 'legitimo', etc.)\n",
    "\n",
    "# 4. Divisão em Treino (70%), Validação (15%) e Teste (15%)\n",
    "# Primeiro, 70% treino e 30% temporário (para val/teste)\n",
    "X_train, X_temp, y_train_binary, y_temp_binary, y_train_multiclass, y_temp_multiclass = train_test_split(\n",
    "    X, y_binary, y_multiclass, \n",
    "    test_size=0.30, \n",
    "    random_state=SEED, \n",
    "    stratify=y_binary # Garantir proporção de fraude\n",
    ")\n",
    "\n",
    "# Segundo, dividir os 30% temporários em 15% validação e 15% teste (50% de 30% = 15%)\n",
    "X_val, X_test, y_val_binary, y_test_binary, y_val_multiclass, y_test_multiclass = train_test_split(\n",
    "    X_temp, y_temp_binary, y_temp_multiclass, \n",
    "    test_size=0.50, # 50% do temp (que era 30% do total)\n",
    "    random_state=SEED, \n",
    "    stratify=y_temp_binary # Garantir proporção de fraude\n",
    ")\n",
    "\n",
    "# Verificar as proporções\n",
    "print(\"--- Divisão dos Dados ---\")\n",
    "print(f\"Treino:   {X_train.shape[0]} amostras\")\n",
    "print(f\"Validação: {X_val.shape[0]} amostras\")\n",
    "print(f\"Teste:    {X_test.shape[0]} amostras\")\n",
    "\n",
    "print(\"\\n--- Proporção de Fraude (Binário) ---\")\n",
    "print(f\"Treino:    {y_train_binary.value_counts(normalize=True)[1]:.4f}\")\n",
    "print(f\"Validação: {y_val_binary.value_counts(normalize=True)[1]:.4f}\")\n",
    "print(f\"Teste:     {y_test_binary.value_counts(normalize=True)[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fcf78a-4e2a-4c11-8727-37f99e4722a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Funções Customizadas para Engenharia de Features de Data/Hora ---\n",
    "\n",
    "def feature_engineer_datetimes(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recebe um DataFrame com as colunas de data/hora e retorna\n",
    "    um DataFrame com features numéricas de engenharia.\n",
    "    \"\"\"\n",
    "    # Criar cópia para evitar SettingWithCopyWarning\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # DataFrame de saída\n",
    "    df_out = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Timestamp atual para cálculos de idade\n",
    "    now = datetime.now()\n",
    "\n",
    "    # 1. 'data_transacao'\n",
    "    dt_tx = pd.to_datetime(df['data_transacao'])\n",
    "    df_out['tx_hora_do_dia'] = dt_tx.dt.hour\n",
    "    df_out['tx_dia_da_semana'] = dt_tx.dt.dayofweek\n",
    "    df_out['tx_mes'] = dt_tx.dt.month\n",
    "\n",
    "    # 2. Idade das Contas (em dias)\n",
    "    df_out['pagador_idade_conta_dias'] = (now - pd.to_datetime(df['pagador_conta_aberta_em'])).dt.days\n",
    "    df_out['recebedor_idade_conta_dias'] = (now - pd.to_datetime(df['recebedor_conta_aberta_em'])).dt.days\n",
    "    \n",
    "    # 3. Idade dos Clientes (em anos)\n",
    "    df_out['pagador_idade_anos'] = ((now - pd.to_datetime(df['pagador_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "    df_out['recebedor_idade_anos'] = ((now - pd.to_datetime(df['recebedor_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "\n",
    "    # Lidar com possíveis nulos que podem ter sido gerados (ex: datas inválidas)\n",
    "    df_out = df_out.fillna(0)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "# --- Definição das Listas de Colunas ---\n",
    "\n",
    "# Colunas numéricas que entram direto no scaler\n",
    "numeric_features = [\n",
    "    'valor_transacao', \n",
    "    'pagador_saldo', \n",
    "    'recebedor_saldo',\n",
    "    'pagador_txs_ultimas_24h',\n",
    "    'pagador_valor_ultimas_24h',\n",
    "    'recebedor_txs_ultima_1h',\n",
    "    'recebedor_valor_ultima_1h',\n",
    "    'pagador_segundos_desde_ultima_tx'\n",
    "]\n",
    "\n",
    "# Colunas categóricas para One-Hot Encoding\n",
    "categorical_features = [\n",
    "    'tipo_iniciacao_pix_id', \n",
    "    'finalidade_pix_id', \n",
    "    'pagador_tipo_conta_id', \n",
    "    'pagador_natureza_id',\n",
    "    'recebedor_tipo_conta_id', \n",
    "    'recebedor_natureza_id'\n",
    "]\n",
    "\n",
    "# Colunas de data/hora para o transformador customizado\n",
    "datetime_features = [\n",
    "    'data_transacao', \n",
    "    'pagador_conta_aberta_em', \n",
    "    'pagador_data_nascimento',\n",
    "    'recebedor_conta_aberta_em', \n",
    "    'recebedor_data_nascimento'\n",
    "]\n",
    "\n",
    "# --- Criação dos Pipelines de Transformação ---\n",
    "\n",
    "# Pipeline para features numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para features categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Pipeline para features de data/hora\n",
    "datetime_transformer = Pipeline(steps=[\n",
    "    ('feature_eng', FunctionTransformer(feature_engineer_datetimes)),\n",
    "    ('scaler', StandardScaler()) # Escalonar as features de data/hora criadas\n",
    "])\n",
    "\n",
    "# --- Montagem do ColumnTransformer (Pré-processador) ---\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('date', datetime_transformer, datetime_features)\n",
    "    ],\n",
    "    remainder='drop' # Ignorar colunas não listadas (ex: IDs)\n",
    ")\n",
    "\n",
    "print(\"Pipeline de pré-processamento 'preprocessor' definido com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864f0950-4ec2-4266-ad11-cf31ec91406e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Função Factory para Modelo Binário ---\n",
    "def build_binary_model(meta):\n",
    "    \"\"\"Constrói o modelo binário para o KerasClassifier.\"\"\"\n",
    "    # scikeras injeta n_features_in_ automaticamente\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    \n",
    "    # Garantir que a semente do TF seja definida dentro da função\n",
    "    # para reprodutibilidade quando o KerasClassifier for clonado\n",
    "    tf.random.set_seed(SEED) \n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid') # Saída sigmoide para binário\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['AUC', tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# --- Função Factory para Modelo Multiclasse ---\n",
    "def build_multiclass_model(meta):\n",
    "    \"\"\"Constrói o modelo multiclasse para o KerasClassifier.\"\"\"\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    # scikeras injeta o número de classes únicas (ex: 3 tipos de fraude)\n",
    "    n_classes_out = meta[\"n_classes_\"]\n",
    "    \n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(n_classes_out, activation='softmax') # Saída softmax\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', # Usar sparse pois os labels são inteiros (0, 1, 2)\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Funções de construção de modelo Keras ('build_binary_model', 'build_multiclass_model') definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0760c1b2-4b7a-4871-9129-3e282dfe1441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definir callback de Early Stopping\n",
    "# Parar o treino se a perda na validação (val_loss) não melhorar após 5 épocas\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 1. Iniciar experimento MLflow\n",
    "mlflow.set_experiment(f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/Pix_Fraud_Detection\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fraud_Binary_Classifier\") as run_binary:\n",
    "    print(f\"Iniciando Run MLflow: {run_binary.info.run_id}\")\n",
    "    \n",
    "    # --- CORREÇÃO AQUI ---\n",
    "    # O 'scikeras.wrappers' moderno usa o argumento 'model' e não 'build_fn'\n",
    "    keras_binary_model = KerasClassifier(\n",
    "        model=build_binary_model,  # <-- MUDANÇA DE 'build_fn' PARA 'model'\n",
    "        epochs=50, \n",
    "        batch_size=256, \n",
    "        verbose=1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "\n",
    "    # 3. Criar o Pipeline completo\n",
    "    pipeline_binary = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', keras_binary_model)\n",
    "    ])\n",
    "\n",
    "    # 4. Pré-processar dados de validação para Early Stopping\n",
    "    # O pipeline.fit não transforma automaticamente os dados passados para 'model__validation_data'\n",
    "    print(\"Pré-ajustando o processador para transformar dados de validação...\")\n",
    "    # Usamos clone() para não \"sujar\" o preprocessor do pipeline antes do .fit()\n",
    "    preprocessor_for_val = clone(preprocessor).fit(X_train)\n",
    "    X_val_processed = preprocessor_for_val.transform(X_val)\n",
    "    print(f\"Dimensões dos dados de validação processados: {X_val_processed.shape}\")\n",
    "    \n",
    "    # 5. Treinar o pipeline\n",
    "    print(\"Iniciando treinamento do pipeline binário...\")\n",
    "    pipeline_binary.fit(\n",
    "        X_train, y_train_binary, \n",
    "        model__validation_data=(X_val_processed, y_val_binary), \n",
    "        model__callbacks=[early_stopping]\n",
    "    )\n",
    "    print(\"Treinamento binário concluído.\")\n",
    "\n",
    "    # 6. Avaliar no set de teste\n",
    "    y_pred_binary_proba = pipeline_binary.predict_proba(X_test)[:, 1]\n",
    "    y_pred_binary = (y_pred_binary_proba >= 0.5).astype(int)\n",
    "\n",
    "    # 7. Logar métricas (Foco em Recall)\n",
    "    recall = recall_score(y_test_binary, y_pred_binary)\n",
    "    precision = precision_score(y_test_binary, y_pred_binary)\n",
    "    f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_binary, y_pred_binary_proba)\n",
    "\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_auc)\n",
    "    \n",
    "    print(\"\\n--- Métricas de Teste (Binário) ---\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {roc_auc:.4f}\")\n",
    "    print(classification_report(y_test_binary, y_pred_binary))\n",
    "\n",
    "    # 8. Salvamento Crítico do Artefato (usará o caminho do Volume)\n",
    "    binary_pipeline_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_binary_pipeline.pkl\")\n",
    "    joblib.dump(pipeline_binary, binary_pipeline_path)\n",
    "    print(f\"Pipeline binário salvo em: {binary_pipeline_path}\")\n",
    "\n",
    "    # 9. Logar no MLflow (modelo e artefato)\n",
    "    signature = infer_signature(X_train, pipeline_binary.predict(X_train))\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_binary, \n",
    "        \"binary_model\", \n",
    "        signature=signature,\n",
    "        input_example=X_train.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    mlflow.log_artifact(binary_pipeline_path)\n",
    "\n",
    "print(\"Célula 6 concluída.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70bd302b-7f85-437e-be82-ef2e2c2664b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Iniciando preparação para o Modelo 2 (Multiclasse)...\")\n",
    "\n",
    "# 1. Filtrar dados para incluir apenas transações fraudulentas\n",
    "train_fraud_mask = (y_train_binary == 1)\n",
    "val_fraud_mask = (y_val_binary == 1)\n",
    "test_fraud_mask = (y_test_binary == 1)\n",
    "\n",
    "X_train_fraud = X_train[train_fraud_mask]\n",
    "y_train_multiclass_fraud = y_train_multiclass[train_fraud_mask]\n",
    "\n",
    "X_val_fraud = X_val[val_fraud_mask]\n",
    "y_val_multiclass_fraud = y_val_multiclass[val_fraud_mask]\n",
    "\n",
    "X_test_fraud = X_test[test_fraud_mask]\n",
    "y_test_multiclass_fraud = y_test_multiclass[test_fraud_mask]\n",
    "\n",
    "print(f\"Total de amostras de fraude para treino: {len(X_train_fraud)}\")\n",
    "print(f\"Total de amostras de fraude para validação: {len(X_val_fraud)}\")\n",
    "print(f\"Total de amostras de fraude para teste: {len(X_test_fraud)}\")\n",
    "\n",
    "# 2. Usar LabelEncoder para converter labels string em inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_multiclass_encoded = label_encoder.fit_transform(y_train_multiclass_fraud)\n",
    "y_val_multiclass_encoded = label_encoder.transform(y_val_multiclass_fraud)\n",
    "y_test_multiclass_encoded = label_encoder.transform(y_test_multiclass_fraud)\n",
    "\n",
    "print(f\"Classes de fraude encontradas: {label_encoder.classes_}\")\n",
    "\n",
    "# 3. Salvamento Crítico (Mapeamento de Labels) (usará o caminho do Volume)\n",
    "# Criar mapa {0: 'scam', 1: 'roubo', 2: 'lavagem'}\n",
    "label_map = {i: str(cls) for i, cls in enumerate(label_encoder.classes_)}\n",
    "label_map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    json.dump(label_map, f, indent=4)\n",
    "print(f\"Mapa de labels salvo em: {label_map_path}\")\n",
    "\n",
    "# --- Treinamento do Modelo Multiclasse ---\n",
    "\n",
    "# Callback para o modelo multiclasse\n",
    "early_stopping_multi = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fraud_Type_Classifier\") as run_multiclass:\n",
    "    print(f\"Iniciando Run MLflow: {run_multiclass.info.run_id}\")\n",
    "    \n",
    "    # --- CORREÇÃO AQUI ---\n",
    "    # O 'scikeras.wrappers' moderno usa o argumento 'model' e não 'build_fn'\n",
    "    keras_multiclass_model = KerasClassifier(\n",
    "        model=build_multiclass_model, # <-- MUDANÇA DE 'build_fn' PARA 'model'\n",
    "        epochs=50, \n",
    "        batch_size=128, \n",
    "        verbose=1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    # --- FIM DA CORREÇÃO ---\n",
    "\n",
    "    # 5. Criar o Pipeline completo\n",
    "    pipeline_multiclass = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', keras_multiclass_model)\n",
    "    ])\n",
    "    \n",
    "    # 6. Pré-processar dados de validação (apenas de fraude)\n",
    "    print(\"Pré-ajustando o processador (multiclasse) nos dados de treino de fraude...\")\n",
    "    # Usamos clone() para não \"sujar\" o preprocessor do pipeline antes do .fit()\n",
    "    preprocessor_multi_for_val = clone(preprocessor).fit(X_train_fraud)\n",
    "    X_val_fraud_processed = preprocessor_multi_for_val.transform(X_val_fraud)\n",
    "    print(f\"Dimensões dos dados de validação (fraude) processados: {X_val_fraud_processed.shape}\")\n",
    "\n",
    "    # 7. Treinar o pipeline (APENAS com dados de fraude)\n",
    "    print(\"Iniciando treinamento do pipeline multiclasse...\")\n",
    "    pipeline_multiclass.fit(\n",
    "        X_train_fraud, y_train_multiclass_encoded, \n",
    "        model__validation_data=(X_val_fraud_processed, y_val_multiclass_encoded), \n",
    "        model__callbacks=[early_stopping_multi]\n",
    "    )\n",
    "    print(\"Treinamento multiclasse concluído.\")\n",
    "\n",
    "    # 8. Avaliar no set de teste (filtrado)\n",
    "    y_pred_multiclass_encoded = pipeline_multiclass.predict(X_test_fraud)\n",
    "    \n",
    "    print(\"\\n--- Métricas de Teste (Multiclasse) ---\")\n",
    "    report_text = classification_report(\n",
    "        y_test_multiclass_encoded, \n",
    "        y_pred_multiclass_encoded, \n",
    "        target_names=label_encoder.classes_\n",
    "    )\n",
    "    print(report_text)\n",
    "    \n",
    "    # Logar métricas\n",
    "    mlflow.log_text(report_text, \"classification_report.txt\")\n",
    "    f1_micro = f1_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='micro')\n",
    "    mlflow.log_metric(\"test_f1_micro\", f1_micro)\n",
    "\n",
    "    # 9. Salvamento Crítico (usará o caminho do Volume)\n",
    "    multiclass_pipeline_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_pipeline.pkl\")\n",
    "    joblib.dump(pipeline_multiclass, multiclass_pipeline_path)\n",
    "    print(f\"Pipeline multiclasse salvo em: {multiclass_pipeline_path}\")\n",
    "\n",
    "    # 10. Logar no MLflow\n",
    "    signature_multi = infer_signature(X_train_fraud, pipeline_multiclass.predict(X_train_fraud))\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_multiclass, \n",
    "        \"multiclass_model\", \n",
    "        signature=signature_multi,\n",
    "        input_example=X_train_fraud.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    mlflow.log_artifact(multiclass_pipeline_path)\n",
    "    mlflow.log_artifact(label_map_path) # Importante logar o mapa também\n",
    "\n",
    "print(\"Célula 7 concluída.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b6b843-4dc9-4648-bca0-7f1e1cbd8d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Iniciando Avaliação Final (Pós-Treino) com Artefatos Salvos ---\")\n",
    "\n",
    "# 1. Carregar artefatos do Volume\n",
    "try:\n",
    "    loaded_pipeline_binary = joblib.load(os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_binary_pipeline.pkl\"))\n",
    "    loaded_pipeline_multiclass = joblib.load(os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_pipeline.pkl\"))\n",
    "    \n",
    "    map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "    with open(map_path, 'r') as f:\n",
    "        # Converter chaves JSON (string) de volta para inteiros\n",
    "        loaded_label_map_str = json.load(f)\n",
    "        loaded_label_map = {int(k): v for k, v in loaded_label_map_str.items()}\n",
    "        \n",
    "    print(\"Artefatos (2 pipelines, 1 mapa) carregados com sucesso do Volume.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro fatal ao carregar artefatos do Volume: {e}\")\n",
    "    # Se falhar aqui, não podemos continuar\n",
    "    raise e\n",
    "\n",
    "# --- Avaliação Modelo 1: Classificação Binária ---\n",
    "print(\"\\n--- Avaliação Modelo 1: Classificação Binária (em X_test) ---\")\n",
    "\n",
    "# Usar os dados de teste reais (y_test_binary)\n",
    "y_pred_binary_loaded = loaded_pipeline_binary.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_binary, y_pred_binary_loaded, target_names=['Legitimo', 'Fraude']))\n",
    "print(\"Matriz de Confusão (Binário):\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_loaded))\n",
    "\n",
    "\n",
    "# --- Avaliação Modelo 2: Classificação Multiclasse ---\n",
    "print(\"\\n--- Avaliação Modelo 2: Classificação Multiclasse (em X_test ONDE y_test==1) ---\")\n",
    "\n",
    "# Filtrar o X_test para incluir apenas as fraudes VERDADEIRAS\n",
    "# (para avaliar o quão bem o 2º modelo classifica os tipos de fraude reais)\n",
    "X_test_true_fraud = X_test[y_test_binary == 1]\n",
    "\n",
    "# --- CORREÇÃO AQUI ---\n",
    "# Usamos 'y_test_multiclass' (o split de teste)\n",
    "# Em vez de 'y_multiclass' (o dataset completo)\n",
    "y_test_true_fraud_labels = y_test_multiclass[y_test_binary == 1]\n",
    "# --- FIM DA CORREÇÃO ---\n",
    "\n",
    "\n",
    "if not X_test_true_fraud.empty:\n",
    "    # Prever os índices (0, 1, 2)\n",
    "    y_pred_multiclass_idx = loaded_pipeline_multiclass.predict(X_test_true_fraud)\n",
    "    \n",
    "    # Mapear os índices de volta para os labels string ('scam', 'roubo')\n",
    "    y_pred_multiclass_labels = [loaded_label_map.get(idx, 'unknown') for idx in y_pred_multiclass_idx]\n",
    "    \n",
    "    # Classes reais para o relatório\n",
    "    true_labels_list = list(loaded_label_map.values())\n",
    "    \n",
    "    print(classification_report(y_test_true_fraud_labels, y_pred_multiclass_labels, labels=true_labels_list))\n",
    "    print(\"Matriz de Confusão (Multiclasse):\")\n",
    "    print(confusion_matrix(y_test_true_fraud_labels, y_pred_multiclass_labels, labels=true_labels_list))\n",
    "else:\n",
    "    print(\"Não foram encontradas fraudes verdadeiras no conjunto de teste para avaliar o modelo multiclasse.\")\n",
    "\n",
    "print(\"\\nCélula 8 concluída. Avaliação final completa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9baeb76-fd04-4546-9232-35ff60270845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Esta célula é 100% AUTÔNOMA e só depende dos artefatos salvos na Célula 6 e 7.\n",
    "# NENHUMA variável ou função das células anteriores é usada here.\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Constantes de Produção ---\n",
    "# Este deve ser o mesmo diretório do Volume usado no treinamento\n",
    "MODEL_DIR = \"/Volumes/transacoes_db/copper/files/pix_fraud/production_artifacts/\"\n",
    "BINARY_THRESHOLD = 0.5 # Threshold de decisão para fraude binária\n",
    "\n",
    "# Suprimir warnings de serialização/versão que podem ocorrer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Carregamento de Artefatos ---\n",
    "\n",
    "def carregar_artefatos(model_dir: str):\n",
    "    \"\"\"\n",
    "    Carrega todos os artefatos necessários (pipelines e mapa de labels)\n",
    "    do diretório especificado (no Volume).\n",
    "    \"\"\"\n",
    "    print(f\"Carregando artefatos de: {model_dir}\")\n",
    "    try:\n",
    "        pipeline_binario = joblib.load(os.path.join(model_dir, \"fraud_binary_pipeline.pkl\"))\n",
    "        pipeline_multiclass = joblib.load(os.path.join(model_dir, \"fraud_type_pipeline.pkl\"))\n",
    "\n",
    "        label_map_path = os.path.join(model_dir, \"fraud_type_label_map.json\")\n",
    "        with open(label_map_path, 'r') as f:\n",
    "            # Converter chaves JSON (string) de volta para inteiros\n",
    "            label_map_str_keys = json.load(f)\n",
    "            label_map = {int(k): v for k, v in label_map_str_keys.items()}\n",
    "            \n",
    "        print(\"Artefatos (2 pipelines, 1 mapa de labels) carregados com sucesso.\")\n",
    "        return pipeline_binario, pipeline_multiclass, label_map\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro crítico: Arquivo de modelo/mapa não encontrado. {e}\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado ao carregar artefatos: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# --- Função de Predição em Cascata ---\n",
    "\n",
    "def prever_fraude(df_novo: pd.DataFrame, pipeline_binario, pipeline_multiclass, label_map) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executa a predição em cascata para novas transações.\n",
    "    Recebe um DataFrame Pandas com o schema exato da view de features.\n",
    "    \"\"\"\n",
    "    if pipeline_binario is None or pipeline_multiclass is None or label_map is None:\n",
    "        raise ValueError(\"Modelos ou mapa de labels não foram carregados corretamente.\")\n",
    "\n",
    "    if not isinstance(df_novo, pd.DataFrame):\n",
    "        df_novo = pd.DataFrame([df_novo])\n",
    "        \n",
    "    df_results = df_novo.copy()\n",
    "\n",
    "    # 1. Modelo Binário\n",
    "    try:\n",
    "        fraud_probabilities = pipeline_binario.predict_proba(df_novo)[:, 1]\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na predição binária: {e}\")\n",
    "        df_results['predicted_fraud'] = np.nan\n",
    "        df_results['fraud_probability'] = np.nan\n",
    "        df_results['predicted_fraud_type'] = None\n",
    "        df_results['predicted_type_probability'] = np.nan\n",
    "        df_results['type_probabilities'] = None\n",
    "        df_results['resumo_da_predicao'] = \"Erro na predição\" # <-- NOVO\n",
    "        return df_results\n",
    "\n",
    "    df_results['fraud_probability'] = fraud_probabilities\n",
    "    df_results['predicted_fraud'] = (fraud_probabilities >= BINARY_THRESHOLD).astype(int)\n",
    "\n",
    "    # Inicializar colunas\n",
    "    df_results['predicted_fraud_type'] = None\n",
    "    df_results['predicted_type_probability'] = np.nan\n",
    "    df_results['type_probabilities'] = [{} for _ in range(len(df_results))]\n",
    "\n",
    "    # 2. Modelo Multiclasse (só para fraudes)\n",
    "    indices_fraude = df_results[df_results['predicted_fraud'] == 1].index\n",
    "\n",
    "    if not indices_fraude.empty:\n",
    "        df_fraude = df_results.loc[indices_fraude]\n",
    "        \n",
    "        try:\n",
    "            type_probs_matrix = pipeline_multiclass.predict_proba(df_fraude)\n",
    "            type_predictions_indices = np.argmax(type_probs_matrix, axis=1)\n",
    "            predicted_type_probs = np.max(type_probs_matrix, axis=1)\n",
    "            predicted_types = [label_map.get(idx, 'unknown') for idx in type_predictions_indices]\n",
    "            \n",
    "            df_results.loc[indices_fraude, 'predicted_fraud_type'] = predicted_types\n",
    "            df_results.loc[indices_fraude, 'predicted_type_probability'] = predicted_type_probs\n",
    "            \n",
    "            type_probs_list = []\n",
    "            for probs_row in type_probs_matrix:\n",
    "                row_dict = {label_map.get(i, 'unknown'): float(prob) for i, prob in enumerate(probs_row)}\n",
    "                type_probs_list.append(row_dict)\n",
    "            \n",
    "            df_results.loc[indices_fraude, 'type_probabilities'] = pd.Series(\n",
    "                type_probs_list, \n",
    "                index=indices_fraude, \n",
    "                dtype='object'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na predição multiclasse: {e}\")\n",
    "            # Se falhar, o tipo de fraude ficará como 'None'\n",
    "\n",
    "    # --- NOVO: LÓGICA DA STRING DE SAÍDA ---\n",
    "    \n",
    "    # 1. Definir o padrão (Não é fraude)\n",
    "    df_results['resumo_da_predicao'] = \"Não é uma fraude.\"\n",
    "    \n",
    "    # 2. Atualizar apenas as linhas que SÃO fraude (usando os índices)\n",
    "    if not indices_fraude.empty:\n",
    "        # Pega os tipos de fraude previstos (ex: 'scam', 'roubo', ou 'None' se a predição multiclasse falhou)\n",
    "        tipos_de_fraude = df_results.loc[indices_fraude, 'predicted_fraud_type']\n",
    "        \n",
    "        # Cria a string formatada\n",
    "        df_results.loc[indices_fraude, 'resumo_da_predicao'] = \"É UMA FRAUDE do tipo \" + tipos_de_fraude.astype(str)\n",
    "        \n",
    "        # Correção para o caso de a predição multiclasse ter falhado e o tipo ser 'None'\n",
    "        df_results['resumo_da_predicao'] = df_results['resumo_da_predicao'].str.replace(\"do tipo None\", \"do tipo desconhecido\")\n",
    "\n",
    "    # --- FIM DA NOVA LÓGICA ---\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# --- Exemplo de Uso (Simulação) ---\n",
    "print(\"\\n--- SIMULANDO EXECUÇÃO DE INFERÊNCIA AUTÔNOMA ---\")\n",
    "\n",
    "# 1. Carregar os artefatos UMA VEZ\n",
    "p_bin, p_multi, l_map = carregar_artefatos(MODEL_DIR)\n",
    "\n",
    "if p_bin and p_multi and l_map:\n",
    "    # 2. Criar um payload de exemplo (usando objetos datetime nativos)\n",
    "    data_exemplo = [\n",
    "        {\n",
    "            # Transação 1: Baixo valor, conta antiga (provavelmente legítima)\n",
    "            'valor_transacao': 50.20,\n",
    "            'data_transacao': datetime.now(),\n",
    "            'tipo_iniciacao_pix_id': 1, 'finalidade_pix_id': 1,\n",
    "            'pagador_saldo': 1500.00, 'pagador_conta_aberta_em': '2018-05-10T10:00:00',\n",
    "            'pagador_tipo_conta_id': 1, 'pagador_natureza_id': 1, 'pagador_data_nascimento': '1985-01-15T00:00:00',\n",
    "            'recebedor_saldo': 3000.00, 'recebedor_conta_aberta_em': '2019-11-20T14:30:00',\n",
    "            'recebedor_tipo_conta_id': 1, 'recebedor_natureza_id': 1, 'recebedor_data_nascimento': '1990-03-22T00:00:00',\n",
    "            'pagador_txs_ultimas_24h': 2, 'pagador_valor_ultimas_24h': 150.0,\n",
    "            'recebedor_txs_ultima_1h': 0, 'recebedor_valor_ultima_1h': 0.0,\n",
    "            'pagador_segundos_desde_ultima_tx': 86400\n",
    "        },\n",
    "        {\n",
    "            # Transação 2: Alto valor, conta nova, de madrugada (suspeita)\n",
    "            'valor_transacao': 4000.00,\n",
    "            'data_transacao': datetime.now().replace(hour=3, minute=30),\n",
    "            'tipo_iniciacao_pix_id': 2, 'finalidade_pix_id': 2,\n",
    "            'pagador_saldo': 4600.00, \n",
    "            'pagador_conta_aberta_em': datetime.now().replace(day=1),\n",
    "            'pagador_tipo_conta_id': 1, 'pagador_natureza_id': 1, 'pagador_data_nascimento': '1998-07-10T00:00:00',\n",
    "            'recebedor_saldo': 0.00, \n",
    "            'recebedor_conta_aberta_em': datetime.now().replace(day=2),\n",
    "            'recebedor_tipo_conta_id': 2, 'recebedor_natureza_id': 2, 'recebedor_data_nascimento': '1999-12-01T00:00:00',\n",
    "            'pagador_txs_ultimas_24h': 1, 'pagador_valor_ultimas_24h': 0,\n",
    "            'recebedor_txs_ultima_1h': 5, 'recebedor_valor_ultima_1h': 0,\n",
    "            'pagador_segundos_desde_ultima_tx': 300\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    payload_exemplo = pd.DataFrame(data_exemplo)\n",
    "    \n",
    "    # 3. Executar predição\n",
    "    print(\"\\nExecutando predição no payload de exemplo...\")\n",
    "    resultados = prever_fraude(payload_exemplo, p_bin, p_multi, l_map)\n",
    "    \n",
    "    print(\"\\nResultados da Predição (Saída):\")\n",
    "    \n",
    "    # --- MODIFICADO: Exibir a nova string de resumo ---\n",
    "    output_columns = ['resumo_da_predicao', 'fraud_probability', 'predicted_type_probability']\n",
    "    \n",
    "    # Configurar pandas para exibir floats com 4 casas decimais\n",
    "    pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000) # Deixa a tabela mais larga\n",
    "    \n",
    "    print(resultados[output_columns])\n",
    "else:\n",
    "    print(\"Simulação de inferência falhou: Artefatos não puderam ser carregados.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7119156965072272,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Treinamento e Teste",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
