{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "895c6e5e-0398-4c09-8cf5-94d572c09fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Configura√ß√µes e Instala√ß√£o de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18d0ce98-7b47-438d-8b5b-ef80c27a8879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.4.2 tensorflow==2.16.1 scikeras==0.13.0 joblib\n",
    "\n",
    "print(\"Depend√™ncias de MLOps instaladas/verificadas.\")\n",
    "print(\"Vers√µes compat√≠veis: scikit-learn==1.4.2, tensorflow==2.16.1, scikeras==0.13.0\")\n",
    "print(\"Reiniciando o kernel Python agora para carregar as novas bibliotecas...\")\n",
    "\n",
    "\n",
    "# Esta fun√ß√£o nativa do Databricks reinicia o kernel Python.\n",
    "# Todas as vari√°veis ser√£o limpas, o que √© o comportamento esperado \n",
    "# ao instalar bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e4b680-1fa5-49b6-82c4-2048826e8894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7373f92d-566b-4027-8f1f-f97baf2757de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a3a7d3-5a0a-4818-a6fc-f0870a94cf8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from mlflow.models.signature import infer_signature\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configura√ß√µes Globais ---\n",
    "# A View de features que j√° existe e ser√° lida\n",
    "VIEW_NAME = \"transacoes_db.feature_store.in_live_features\"\n",
    "\n",
    "# --- MUDAN√áA PRINCIPAL AQUI ---\n",
    "# Diret√≥rio em seu Volume do Unity Catalog para salvar os artefatos\n",
    "# (Assumindo que voc√™ queira manter uma subpasta 'pix_fraud' dentro do volume)\n",
    "MODEL_ARTIFACTS_DIR = \"/Volumes/transacoes_db/copper/files/pix_fraud/production_artifacts/\"\n",
    "# --- FIM DA MUDAN√áA ---\n",
    "\n",
    "# Semente para reprodutibilidade\n",
    "SEED = 42\n",
    "\n",
    "# --- Configura√ß√µes de Ambiente ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Garantir que o diret√≥rio de artefatos exista no Volume\n",
    "os.makedirs(MODEL_ARTIFACTS_DIR, exist_ok=True)\n",
    "print(f\"Diret√≥rio de artefatos garantido: {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "# --- Sementes de Aleatoriedade ---\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Inicializar SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f84d8574-7052-4089-9393-ea6ee4d55c09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* CONTEXTO DA VIEW: transacoes_db.feature_store.in_live_features\n",
    "(Esta c√©lula %sql √© apenas para documenta√ß√£o, a view j√° existe)\n",
    "\n",
    "Esta view agrega dados transacionais com perfis e features de janela temporal.\n",
    "*\n",
    "SELECT\n",
    "  -- Colunas da transa√ß√£o\n",
    "  ft.valor AS valor_transacao,\n",
    "  ft.data AS data_transacao,\n",
    "  ft.id_conta_origem AS id_conta_pagador,\n",
    "  ft.id_conta_destino AS id_conta_recebedor,\n",
    "  ft.id_tipo_iniciacao_pix AS tipo_iniciacao_pix_id,\n",
    "  ft.id_finalidade_pix AS finalidade_pix_id,\n",
    "  \n",
    "  -- Targets (R√≥tulos)\n",
    "  ft.is_fraud AS transacao_fraudulenta, -- (Bin√°rio: 0 ou 1)\n",
    "  ft.fraud_type AS tipo_fraude,         -- (Multiclasse: 'scam', 'roubo', etc.)\n",
    "\n",
    "  -- Perfis (Pagador e Recebedor)\n",
    "  conta_orig.saldo AS pagador_saldo,\n",
    "  conta_orig.aberta_em AS pagador_conta_aberta_em,\n",
    "  conta_orig.id_tipo_conta AS pagador_tipo_conta_id,\n",
    "  cliente_orig.id_natureza AS pagador_natureza_id,\n",
    "  cliente_orig.nascido_em AS pagador_data_nascimento,\n",
    "  conta_dest.saldo AS recebedor_saldo,\n",
    "  conta_dest.aberta_em AS recebedor_conta_aberta_em,\n",
    "  conta_dest.id_tipo_conta AS recebedor_tipo_conta_id,\n",
    "  cliente_dest.id_natureza AS recebedor_natureza_id,\n",
    "  cliente_dest.nascido_em AS recebedor_data_nascimento,\n",
    "\n",
    "  -- Features de Tempo Real (Window Functions)\n",
    "  ft.pagador_txs_ultimas_24h,\n",
    "  ft.pagador_valor_ultimas_24h,\n",
    "  ft.recebedor_txs_ultima_1h,\n",
    "  ft.recebedor_valor_ultima_1h,\n",
    "  ft.pagador_segundos_desde_ultima_tx\n",
    "FROM\n",
    "  transacoes_db.feature_store.in_live_features AS ft\n",
    "... (JOINS com tabelas copper de perfis) ...\n",
    "limit 1 */\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a9f650d-c319-4df0-a224-c8437d25d86b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Carregamento e Pre-Processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651ce2fe-40e6-4f04-8086-3e583b471ac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Carregando dados da view: {VIEW_NAME}...\")\n",
    "# 1. Carregar dados do Delta Lake (Spark)\n",
    "df_spark = spark.read.table(VIEW_NAME)\n",
    "\n",
    "# 2. Converter para Pandas\n",
    "# Assumindo que o dataset cabe na mem√≥ria do driver para treinamento com Sklearn/Keras\n",
    "df_pandas = df_spark.toPandas()\n",
    "print(f\"Dados carregados. Total de {len(df_pandas)} registros.\")\n",
    "\n",
    "# 3. Separar Features (X) e Targets (y)\n",
    "# IDs n√£o s√£o features para o modelo\n",
    "features_to_drop = ['transacao_fraudulenta', 'tipo_fraude', 'id_conta_pagador', 'id_conta_recebedor']\n",
    "X = df_pandas.drop(columns=features_to_drop)\n",
    "y_binary = df_pandas['transacao_fraudulenta']\n",
    "y_multiclass = df_pandas['tipo_fraude'] # Este ainda √© string ('scam', 'legitimo', etc.)\n",
    "\n",
    "# 4. Divis√£o em Treino (70%), Valida√ß√£o (15%) e Teste (15%)\n",
    "# Primeiro, 70% treino e 30% tempor√°rio (para val/teste)\n",
    "X_train, X_temp, y_train_binary, y_temp_binary, y_train_multiclass, y_temp_multiclass = train_test_split(\n",
    "    X, y_binary, y_multiclass, \n",
    "    test_size=0.30, \n",
    "    random_state=SEED, \n",
    "    stratify=y_binary # Garantir propor√ß√£o de fraude\n",
    ")\n",
    "\n",
    "# Segundo, dividir os 30% tempor√°rios em 15% valida√ß√£o e 15% teste (50% de 30% = 15%)\n",
    "X_val, X_test, y_val_binary, y_test_binary, y_val_multiclass, y_test_multiclass = train_test_split(\n",
    "    X_temp, y_temp_binary, y_temp_multiclass, \n",
    "    test_size=0.50, # 50% do temp (que era 30% do total)\n",
    "    random_state=SEED, \n",
    "    stratify=y_temp_binary # Garantir propor√ß√£o de fraude\n",
    ")\n",
    "\n",
    "# Verificar as propor√ß√µes\n",
    "print(\"--- Divis√£o dos Dados ---\")\n",
    "print(f\"Treino:   {X_train.shape[0]} amostras\")\n",
    "print(f\"Valida√ß√£o: {X_val.shape[0]} amostras\")\n",
    "print(f\"Teste:    {X_test.shape[0]} amostras\")\n",
    "\n",
    "print(\"\\n--- Propor√ß√£o de Fraude (Bin√°rio) ---\")\n",
    "print(f\"Treino:    {y_train_binary.value_counts(normalize=True)[1]:.4f}\")\n",
    "print(f\"Valida√ß√£o: {y_val_binary.value_counts(normalize=True)[1]:.4f}\")\n",
    "print(f\"Teste:     {y_test_binary.value_counts(normalize=True)[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de414df-e05b-431c-91e3-89a98db58cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Fun√ß√µes para Treinamento do Modelo / Defini√ß√£o de Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fcf78a-4e2a-4c11-8727-37f99e4722a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Fun√ß√µes Customizadas para Engenharia de Features de Data/Hora ---\n",
    "\n",
    "def feature_engineer_datetimes(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recebe um DataFrame com as colunas de data/hora e retorna\n",
    "    um DataFrame com features num√©ricas de engenharia.\n",
    "    \"\"\"\n",
    "    # Criar c√≥pia para evitar SettingWithCopyWarning\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # DataFrame de sa√≠da\n",
    "    df_out = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Timestamp atual para c√°lculos de idade\n",
    "    now = datetime.now()\n",
    "\n",
    "    # 1. 'data_transacao'\n",
    "    dt_tx = pd.to_datetime(df['data_transacao'])\n",
    "    df_out['tx_hora_do_dia'] = dt_tx.dt.hour\n",
    "    df_out['tx_dia_da_semana'] = dt_tx.dt.dayofweek\n",
    "    df_out['tx_mes'] = dt_tx.dt.month\n",
    "\n",
    "    # 2. Idade das Contas (em dias)\n",
    "    # df_out['pagador_idade_conta_dias'] = (now - pd.to_datetime(df['pagador_conta_aberta_em'])).dt.days    # REMOVIDO: Agora vem diretamente do SQL\n",
    "    df_out['recebedor_idade_conta_dias'] = (now - pd.to_datetime(df['recebedor_conta_aberta_em'])).dt.days\n",
    "    \n",
    "    # 3. Idade dos Clientes (em anos)\n",
    "    df_out['pagador_idade_anos'] = ((now - pd.to_datetime(df['pagador_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "    df_out['recebedor_idade_anos'] = ((now - pd.to_datetime(df['recebedor_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "\n",
    "    # Lidar com poss√≠veis nulos que podem ter sido gerados (ex: datas inv√°lidas)\n",
    "    df_out = df_out.fillna(0)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "# --- Defini√ß√£o das Listas de Colunas ---\n",
    "\n",
    "# Colunas num√©ricas que entram direto no scaler\n",
    "numeric_features = [\n",
    "    'valor_transacao', \n",
    "    'pagador_saldo', \n",
    "    'recebedor_saldo',\n",
    "    'pagador_txs_ultimas_24h',\n",
    "    'pagador_valor_ultimas_24h',\n",
    "    'recebedor_txs_ultima_1h',\n",
    "    'recebedor_valor_ultima_1h',\n",
    "    'pagador_segundos_desde_ultima_tx',\n",
    "    \n",
    "    # --- Novas Features (Adicionadas do SQL) ---\n",
    "    'primeira_interacao',\n",
    "    'pagador_interacoes_com_recebedor',\n",
    "    'recebedor_num_pagadores_unicos_24h',\n",
    "    'recebedor_idade_conta_dias',\n",
    "    'pagador_idade_conta_dias',\n",
    "    'valor_vs_media_pagador_30d',\n",
    "    'valor_vs_saldo_pagador'\n",
    "]\n",
    "\n",
    "# Colunas categ√≥ricas para One-Hot Encoding\n",
    "categorical_features = [\n",
    "    'tipo_iniciacao_pix_id', \n",
    "    'finalidade_pix_id', \n",
    "    'pagador_tipo_conta_id', \n",
    "    'pagador_natureza_id',\n",
    "    'recebedor_tipo_conta_id', \n",
    "    'recebedor_natureza_id'\n",
    "]\n",
    "\n",
    "# Colunas de data/hora para o transformador customizado\n",
    "datetime_features = [\n",
    "    'data_transacao', \n",
    "    'pagador_conta_aberta_em', \n",
    "    'pagador_data_nascimento',\n",
    "    'recebedor_conta_aberta_em', \n",
    "    'recebedor_data_nascimento'\n",
    "]\n",
    "\n",
    "# --- Cria√ß√£o dos Pipelines de Transforma√ß√£o ---\n",
    "\n",
    "# Pipeline para features num√©ricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # ADICIONADO para tratar NULLs\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline para features categ√≥ricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Pipeline para features de data/hora\n",
    "datetime_transformer = Pipeline(steps=[\n",
    "    ('feature_eng', FunctionTransformer(feature_engineer_datetimes)),\n",
    "    ('scaler', StandardScaler()) # Escalonar as features de data/hora criadas\n",
    "])\n",
    "\n",
    "# --- Montagem do ColumnTransformer (Pr√©-processador) ---\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('date', datetime_transformer, datetime_features)\n",
    "    ],\n",
    "    remainder='drop' # Ignorar colunas n√£o listadas (ex: IDs)\n",
    ")\n",
    "\n",
    "print(\"Pipeline de pr√©-processamento 'preprocessor' definido com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a137f5e-6ce7-4116-959f-9befaef0ba81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fun√ß√µes de Cria√ß√£o de modelo Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864f0950-4ec2-4266-ad11-cf31ec91406e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Fun√ß√£o Factory para Modelo Bin√°rio ---\n",
    "def build_binary_model(meta):\n",
    "    \"\"\"Constr√≥i o modelo bin√°rio para o KerasClassifier.\"\"\"\n",
    "    # scikeras injeta n_features_in_ automaticamente\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    \n",
    "    # Garantir que a semente do TF seja definida dentro da fun√ß√£o\n",
    "    # para reprodutibilidade quando o KerasClassifier for clonado\n",
    "    tf.random.set_seed(SEED) \n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid') # Sa√≠da sigmoide para bin√°rio\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['AUC', tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# --- Fun√ß√£o Factory para Modelo Multiclasse ---\n",
    "def build_multiclass_model(meta):\n",
    "    \"\"\"Constr√≥i o modelo multiclasse para o KerasClassifier.\"\"\"\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    # scikeras injeta o n√∫mero de classes √∫nicas (ex: 3 tipos de fraude)\n",
    "    n_classes_out = meta[\"n_classes_\"]\n",
    "    \n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(n_classes_out, activation='softmax') # Sa√≠da softmax\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', # Usar sparse pois os labels s√£o inteiros (0, 1, 2)\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Fun√ß√µes de constru√ß√£o de modelo Keras ('build_binary_model', 'build_multiclass_model') definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cfe2910-6427-4501-b242-264bcd9ab18e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Treinamento do modelo Binario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0760c1b2-4b7a-4871-9129-3e282dfe1441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Definir callback de Early Stopping\n",
    "# Parar o treino se a perda na valida√ß√£o (val_loss) n√£o melhorar ap√≥s 5 √©pocas\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 1. Iniciar experimento MLflow\n",
    "mlflow.set_experiment(f\"/Users/{dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()}/Pix_Fraud_Detection\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fraud_Binary_Classifier\") as run_binary:\n",
    "    print(f\"Iniciando Run MLflow: {run_binary.info.run_id}\")\n",
    "    \n",
    "    # --- CORRE√á√ÉO AQUI ---\n",
    "    # O 'scikeras.wrappers' moderno usa o argumento 'model' e n√£o 'build_fn'\n",
    "    keras_binary_model = KerasClassifier(\n",
    "        model=build_binary_model,  # <-- MUDAN√áA DE 'build_fn' PARA 'model'\n",
    "        epochs=50, \n",
    "        batch_size=256, \n",
    "        verbose=1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    # --- FIM DA CORRE√á√ÉO ---\n",
    "\n",
    "    # 3. Criar o Pipeline completo\n",
    "    pipeline_binary = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', keras_binary_model)\n",
    "    ])\n",
    "\n",
    "    # 4. Pr√©-processar dados de valida√ß√£o para Early Stopping\n",
    "    # O pipeline.fit n√£o transforma automaticamente os dados passados para 'model__validation_data'\n",
    "    print(\"Pr√©-ajustando o processador para transformar dados de valida√ß√£o...\")\n",
    "    # Usamos clone() para n√£o \"sujar\" o preprocessor do pipeline antes do .fit()\n",
    "    preprocessor_for_val = clone(preprocessor).fit(X_train)\n",
    "    X_val_processed = preprocessor_for_val.transform(X_val)\n",
    "    print(f\"Dimens√µes dos dados de valida√ß√£o processados: {X_val_processed.shape}\")\n",
    "    \n",
    "    # 5. Treinar o pipeline\n",
    "    print(\"Iniciando treinamento do pipeline bin√°rio...\")\n",
    "    pipeline_binary.fit(\n",
    "        X_train, y_train_binary, \n",
    "        model__validation_data=(X_val_processed, y_val_binary), \n",
    "        model__callbacks=[early_stopping]\n",
    "    )\n",
    "    print(\"Treinamento bin√°rio conclu√≠do.\")\n",
    "\n",
    "    # 6. Avaliar no set de teste\n",
    "    y_pred_binary_proba = pipeline_binary.predict_proba(X_test)[:, 1]\n",
    "    y_pred_binary = (y_pred_binary_proba >= 0.5).astype(int)\n",
    "\n",
    "    # 7. Logar m√©tricas (Foco em Recall)\n",
    "    recall = recall_score(y_test_binary, y_pred_binary)\n",
    "    precision = precision_score(y_test_binary, y_pred_binary)\n",
    "    f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_binary, y_pred_binary_proba)\n",
    "\n",
    "    mlflow.log_metric(\"test_recall\", recall)\n",
    "    mlflow.log_metric(\"test_precision\", precision)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_auc)\n",
    "    \n",
    "    print(\"\\n--- M√©tricas de Teste (Bin√°rio) ---\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(f\"ROC AUC:   {roc_auc:.4f}\")\n",
    "    print(classification_report(y_test_binary, y_pred_binary))\n",
    "\n",
    "    # 8. Salvamento Cr√≠tico do Artefato (usar√° o caminho do Volume)\n",
    "    binary_pipeline_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_binary_pipeline.pkl\")\n",
    "    joblib.dump(pipeline_binary, binary_pipeline_path)\n",
    "    print(f\"Pipeline bin√°rio salvo em: {binary_pipeline_path}\")\n",
    "\n",
    "    # 9. Logar no MLflow (modelo e artefato)\n",
    "    signature = infer_signature(X_train, pipeline_binary.predict(X_train))\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_binary, \n",
    "        \"binary_model\", \n",
    "        signature=signature,\n",
    "        input_example=X_train.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    mlflow.log_artifact(binary_pipeline_path)\n",
    "\n",
    "print(\"C√©lula 6 conclu√≠da.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b006f7c-0f5c-40f8-95ad-766550343e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analise Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "58736326-95d8-44a9-b16e-1e70e317a0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Defini√ß√£o da Fun√ß√£o (J√° ajustada para imprimir resultados)\n",
    "def plot_learning_curve(model, X, y, title=\"Curva de Aprendizado\", \n",
    "                        cv=5, \n",
    "                        train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                        scoring='f1'): # Adicionado 'scoring' como par√¢metro para clareza\n",
    "    \"\"\"\n",
    "    Plota a curva de aprendizado e imprime os scores m√©dios.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Informa quantos treinamentos ser√£o feitos\n",
    "    total_fits = len(train_sizes) * cv\n",
    "    print(f\"Calculando curva de aprendizado... Total de {total_fits} treinamentos.\")\n",
    "\n",
    "    # A fun√ß√£o learning_curve retorna os tamanhos absolutos usados\n",
    "    train_sizes_abs, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=cv, scoring=scoring, n_jobs=-1,\n",
    "        train_sizes=train_sizes, shuffle=True, random_state=42\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "\n",
    "    # --- O \"Resultado Direto\" ---\n",
    "    print(\"\\n--- Resultados (M√©dias) ---\")\n",
    "    print(f\"{'Tamanho Treino':<15} | {'F1 Treino':<10} | {'F1 Valida√ß√£o':<10}\")\n",
    "    print(\"-\" * 47)\n",
    "    for i, size in enumerate(train_sizes_abs):\n",
    "        print(f\"{size:<15} | {train_mean[i]:<10.4f} | {val_mean[i]:<10.4f}\")\n",
    "    print(\"---------------------------\\n\")\n",
    "    # -----------------------------\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(train_sizes_abs, train_mean, 'o-', label=\"Treino\", linewidth=2)\n",
    "    plt.plot(train_sizes_abs, val_mean, 'o-', label=\"Valida√ß√£o\", linewidth=2)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Tamanho do conjunto de treino (N¬∫ de amostras)\")\n",
    "    plt.ylabel(\"F1-Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# --- 2. Defini√ß√£o dos par√¢metros para rodar r√°pido ---\n",
    "cv_rapido = 3\n",
    "tamanhos_rapidos = np.linspace(0.25, 1.0, 3) # 3 pontos (25%, 62.5%, 100%)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71e41169-259d-4501-a127-bfd07ed517c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(\n",
    "#     pipeline_binary, \n",
    "#     X_train, \n",
    "#     y_train_binary, \n",
    "#     title=\"Curva de Aprendizado - Modelo Bin√°rio (R√°pida)\", \n",
    "#     cv=cv_rapido, \n",
    "#     train_sizes=tamanhos_rapidos,\n",
    "#     scoring='f1' # Scoring correto para o bin√°rio\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe769f9b-65a9-4e4f-8bb3-12e6d324c637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìä COMPARATIVO DE M√âTRICAS ENTRE TREINO E TESTE - MODELO BIN√ÅRIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Calcular m√©tricas no treino\n",
    "y_pred_train = pipeline_binary.predict(X_train)\n",
    "y_pred_train_proba = pipeline_binary.predict_proba(X_train)[:, 1]\n",
    "\n",
    "recall_train = recall_score(y_train_binary, y_pred_train)\n",
    "precision_train = precision_score(y_train_binary, y_pred_train)\n",
    "f1_train = f1_score(y_train_binary, y_pred_train)\n",
    "roc_auc_train = roc_auc_score(y_train_binary, y_pred_train_proba)\n",
    "\n",
    "metrics_data = {\n",
    "    'Conjunto': ['Treino', 'Teste'],\n",
    "    'Recall': [recall_train, recall],\n",
    "    'Precision': [precision_train, precision],\n",
    "    'F1-Score': [f1_train, f1],\n",
    "    'ROC AUC': [roc_auc_train, roc_auc]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "df_metrics_melt = df_metrics.melt(id_vars='Conjunto', var_name='M√©trica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x='M√©trica', y='Valor', hue='Conjunto', data=df_metrics_melt, palette='viridis')\n",
    "plt.title('Comparativo de M√©tricas - Treino vs Teste (Modelo Bin√°rio)', fontsize=14)\n",
    "plt.ylim(0.85, 1.0)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b97fdc1-b7e2-4509-ba35-b5f147114087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìà DISPERS√ÉO DAS PROBABILIDADES PREDITAS - MODELO BIN√ÅRIO\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=range(len(y_test_binary)), y=y_pred_binary_proba,\n",
    "                hue=y_test_binary, palette=['#2ecc71','#e74c3c'], alpha=0.6)\n",
    "plt.title('Dispers√£o das Probabilidades Previstas - Modelo Bin√°rio', fontsize=14)\n",
    "plt.xlabel('√çndice da Amostra')\n",
    "plt.ylabel('Probabilidade Prevista de Fraude')\n",
    "plt.legend(title='Classe Real', labels=['N√£o Fraude','Fraude'])\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c75f9b-a3f5-4e1d-b33d-2ee8d8e82c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üß© MATRIZ DE CONFUS√ÉO ESTILIZADA - MODELO BIN√ÅRIO\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax, colorbar=False)\n",
    "plt.title('Matriz de Confus√£o - Modelo Bin√°rio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2084ceba-0a09-4674-b687-8d63a962ae30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Treinamento do Modelo Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70bd302b-7f85-437e-be82-ef2e2c2664b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Iniciando prepara√ß√£o para o Modelo 2 (Multiclasse)...\")\n",
    "\n",
    "# 1. Filtrar dados para incluir apenas transa√ß√µes fraudulentas\n",
    "train_fraud_mask = (y_train_binary == 1)\n",
    "val_fraud_mask = (y_val_binary == 1)\n",
    "test_fraud_mask = (y_test_binary == 1)\n",
    "\n",
    "X_train_fraud = X_train[train_fraud_mask]\n",
    "y_train_multiclass_fraud = y_train_multiclass[train_fraud_mask]\n",
    "\n",
    "X_val_fraud = X_val[val_fraud_mask]\n",
    "y_val_multiclass_fraud = y_val_multiclass[val_fraud_mask]\n",
    "\n",
    "X_test_fraud = X_test[test_fraud_mask]\n",
    "y_test_multiclass_fraud = y_test_multiclass[test_fraud_mask]\n",
    "\n",
    "print(f\"Total de amostras de fraude para treino: {len(X_train_fraud)}\")\n",
    "print(f\"Total de amostras de fraude para valida√ß√£o: {len(X_val_fraud)}\")\n",
    "print(f\"Total de amostras de fraude para teste: {len(X_test_fraud)}\")\n",
    "\n",
    "# 2. Usar LabelEncoder para converter labels string em inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_multiclass_encoded = label_encoder.fit_transform(y_train_multiclass_fraud)\n",
    "y_val_multiclass_encoded = label_encoder.transform(y_val_multiclass_fraud)\n",
    "y_test_multiclass_encoded = label_encoder.transform(y_test_multiclass_fraud)\n",
    "\n",
    "print(f\"Classes de fraude encontradas: {label_encoder.classes_}\")\n",
    "\n",
    "# 3. Salvamento Cr√≠tico (Mapeamento de Labels) (usar√° o caminho do Volume)\n",
    "# Criar mapa {0: 'scam', 1: 'roubo', 2: 'lavagem'}\n",
    "label_map = {i: str(cls) for i, cls in enumerate(label_encoder.classes_)}\n",
    "label_map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    json.dump(label_map, f, indent=4)\n",
    "print(f\"Mapa de labels salvo em: {label_map_path}\")\n",
    "\n",
    "# --- Treinamento do Modelo Multiclasse ---\n",
    "\n",
    "# Callback para o modelo multiclasse\n",
    "early_stopping_multi = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fraud_Type_Classifier\") as run_multiclass:\n",
    "    print(f\"Iniciando Run MLflow: {run_multiclass.info.run_id}\")\n",
    "    \n",
    "\n",
    "    keras_multiclass_model = KerasClassifier(\n",
    "        model=build_multiclass_model, # <-- MUDAN√áA DE 'build_fn' PARA 'model'\n",
    "        epochs=50, \n",
    "        batch_size=128, \n",
    "        verbose=1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    # --- FIM DA CORRE√á√ÉO ---\n",
    "\n",
    "    # 5. Criar o Pipeline completo\n",
    "    pipeline_multiclass = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', keras_multiclass_model)\n",
    "    ])\n",
    "    \n",
    "    # 6. Pr√©-processar dados de valida√ß√£o (apenas de fraude)\n",
    "    print(\"Pr√©-ajustando o processador (multiclasse) nos dados de treino de fraude...\")\n",
    "    # Usamos clone() para n√£o \"sujar\" o preprocessor do pipeline antes do .fit()\n",
    "    preprocessor_multi_for_val = clone(preprocessor).fit(X_train_fraud)\n",
    "    X_val_fraud_processed = preprocessor_multi_for_val.transform(X_val_fraud)\n",
    "    print(f\"Dimens√µes dos dados de valida√ß√£o (fraude) processados: {X_val_fraud_processed.shape}\")\n",
    "\n",
    "    # 7. Treinar o pipeline (APENAS com dados de fraude)\n",
    "    print(\"Iniciando treinamento do pipeline multiclasse...\")\n",
    "    pipeline_multiclass.fit(\n",
    "        X_train_fraud, y_train_multiclass_encoded, \n",
    "        model__validation_data=(X_val_fraud_processed, y_val_multiclass_encoded), \n",
    "        model__callbacks=[early_stopping_multi]\n",
    "    )\n",
    "    print(\"Treinamento multiclasse conclu√≠do.\")\n",
    "\n",
    "    # 8. Avaliar no set de teste (filtrado)\n",
    "    y_pred_multiclass_encoded = pipeline_multiclass.predict(X_test_fraud)\n",
    "    \n",
    "    print(\"\\n--- M√©tricas de Teste (Multiclasse) ---\")\n",
    "    report_text = classification_report(\n",
    "        y_test_multiclass_encoded, \n",
    "        y_pred_multiclass_encoded, \n",
    "        target_names=label_encoder.classes_\n",
    "    )\n",
    "    print(report_text)\n",
    "    \n",
    "    # Logar m√©tricas\n",
    "    mlflow.log_text(report_text, \"classification_report.txt\")\n",
    "    f1_micro = f1_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='micro')\n",
    "    mlflow.log_metric(\"test_f1_micro\", f1_micro)\n",
    "\n",
    "    # 9. Salvamento Cr√≠tico (usar√° o caminho do Volume)\n",
    "    multiclass_pipeline_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_pipeline.pkl\")\n",
    "    joblib.dump(pipeline_multiclass, multiclass_pipeline_path)\n",
    "    print(f\"Pipeline multiclasse salvo em: {multiclass_pipeline_path}\")\n",
    "\n",
    "    # 10. Logar no MLflow\n",
    "    signature_multi = infer_signature(X_train_fraud, pipeline_multiclass.predict(X_train_fraud))\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_multiclass, \n",
    "        \"multiclass_model\", \n",
    "        signature=signature_multi,\n",
    "        input_example=X_train_fraud.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    mlflow.log_artifact(multiclass_pipeline_path)\n",
    "    mlflow.log_artifact(label_map_path) # Importante logar o mapa tamb√©m\n",
    "\n",
    "print(\"C√©lula 7 conclu√≠da.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755e210a-e23f-4dde-a984-14ba1dbe57e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analise Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de368e1-6d0f-4140-aa9b-6c7272903568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(\n",
    "#     pipeline_multiclass, \n",
    "#     X_train, \n",
    "#     y_train_binary, \n",
    "#     title=\"urva de Aprendizado - Modelo Multiclasse\", \n",
    "#     cv=cv_rapido, \n",
    "#     train_sizes=tamanhos_rapidos\n",
    "#     #scoring='f1' # Scoring correto para o bin√°rio\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c86138d8-7efa-4ad8-a344-267d18ccb01b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìä COMPARATIVO DE M√âTRICAS ENTRE TREINO E TESTE - MODELO MULTICLASSE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Previs√µes no treino\n",
    "y_pred_train_multiclass = pipeline_multiclass.predict(X_train_fraud)\n",
    "\n",
    "# M√©tricas no treino\n",
    "recall_train = recall_score(y_train_multiclass_encoded, y_pred_train_multiclass, average='macro')\n",
    "precision_train = precision_score(y_train_multiclass_encoded, y_pred_train_multiclass, average='macro')\n",
    "f1_train = f1_score(y_train_multiclass_encoded, y_pred_train_multiclass, average='macro')\n",
    "\n",
    "# M√©tricas no teste (usando vari√°veis j√° calculadas)\n",
    "recall_test = recall_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='macro')\n",
    "precision_test = precision_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='macro')\n",
    "f1_test = f1_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='macro')\n",
    "\n",
    "metrics_data = {\n",
    "    'Conjunto': ['Treino', 'Teste'],\n",
    "    'Recall (Macro)': [recall_train, recall_test],\n",
    "    'Precision (Macro)': [precision_train, precision_test],\n",
    "    'F1-Score (Macro)': [f1_train, f1_test]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "df_metrics_melt = df_metrics.melt(id_vars='Conjunto', var_name='M√©trica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x='M√©trica', y='Valor', hue='Conjunto', data=df_metrics_melt, palette='mako')\n",
    "plt.title('Comparativo de M√©tricas - Treino vs Teste (Modelo Multiclasse)', fontsize=14)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b75f2d2-1947-4544-8028-cc3a7f8063cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìà DISPERS√ÉO DAS PREDI√á√ïES POR CLASSE - MODELO MULTICLASSE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduz dimensionalidade para 2D para visualiza√ß√£o\n",
    "X_test_fraud_transformed = pipeline_multiclass.named_steps['preprocessor'].transform(X_test_fraud)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_2d = pca.fit_transform(X_test_fraud_transformed)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_2d[:,0], y=X_2d[:,1], hue=[label_encoder.classes_[i] for i in y_pred_multiclass_encoded],\n",
    "                palette='tab10', alpha=0.7)\n",
    "plt.title('Dispers√£o das Predi√ß√µes por Tipo de Fraude (PCA 2D)', fontsize=14)\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Classe Prevista', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe63022-f156-4443-bcd4-b59a1720ef15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üß© MATRIZ DE CONFUS√ÉO - MODELO MULTICLASSE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm_multi = confusion_matrix(y_test_multiclass_encoded, y_pred_multiclass_encoded)\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_multi, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap='Purples', ax=ax, colorbar=False)\n",
    "plt.title('Matriz de Confus√£o - Modelo Multiclasse')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e31568d-5eab-4dcd-b1fc-102da8a3cee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Avalia√ß√£o Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b6b843-4dc9-4648-bca0-7f1e1cbd8d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Iniciando Avalia√ß√£o Final (P√≥s-Treino) com Artefatos Salvos ---\")\n",
    "\n",
    "# 1. Carregar artefatos do Volume\n",
    "try:\n",
    "    loaded_pipeline_binary = joblib.load(os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_binary_pipeline.pkl\"))\n",
    "    loaded_pipeline_multiclass = joblib.load(os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_pipeline.pkl\"))\n",
    "    \n",
    "    map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "    with open(map_path, 'r') as f:\n",
    "        # Converter chaves JSON (string) de volta para inteiros\n",
    "        loaded_label_map_str = json.load(f)\n",
    "        loaded_label_map = {int(k): v for k, v in loaded_label_map_str.items()}\n",
    "        \n",
    "    print(\"Artefatos (2 pipelines, 1 mapa) carregados com sucesso do Volume.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro fatal ao carregar artefatos do Volume: {e}\")\n",
    "    # Se falhar aqui, n√£o podemos continuar\n",
    "    raise e\n",
    "\n",
    "# --- Avalia√ß√£o Modelo 1: Classifica√ß√£o Bin√°ria ---\n",
    "print(\"\\n--- Avalia√ß√£o Modelo 1: Classifica√ß√£o Bin√°ria (em X_test) ---\")\n",
    "\n",
    "# Usar os dados de teste reais (y_test_binary)\n",
    "y_pred_binary_loaded = loaded_pipeline_binary.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_binary, y_pred_binary_loaded, target_names=['Legitimo', 'Fraude']))\n",
    "print(\"Matriz de Confus√£o (Bin√°rio):\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_loaded))\n",
    "\n",
    "\n",
    "# --- Avalia√ß√£o Modelo 2: Classifica√ß√£o Multiclasse ---\n",
    "print(\"\\n--- Avalia√ß√£o Modelo 2: Classifica√ß√£o Multiclasse (em X_test ONDE y_test==1) ---\")\n",
    "\n",
    "# Filtrar o X_test para incluir apenas as fraudes VERDADEIRAS\n",
    "# (para avaliar o qu√£o bem o 2¬∫ modelo classifica os tipos de fraude reais)\n",
    "X_test_true_fraud = X_test[y_test_binary == 1]\n",
    "\n",
    "# --- CORRE√á√ÉO AQUI ---\n",
    "# Usamos 'y_test_multiclass' (o split de teste)\n",
    "# Em vez de 'y_multiclass' (o dataset completo)\n",
    "y_test_true_fraud_labels = y_test_multiclass[y_test_binary == 1]\n",
    "# --- FIM DA CORRE√á√ÉO ---\n",
    "\n",
    "\n",
    "if not X_test_true_fraud.empty:\n",
    "    # Prever os √≠ndices (0, 1, 2)\n",
    "    y_pred_multiclass_idx = loaded_pipeline_multiclass.predict(X_test_true_fraud)\n",
    "    \n",
    "    # Mapear os √≠ndices de volta para os labels string ('scam', 'roubo')\n",
    "    y_pred_multiclass_labels = [loaded_label_map.get(idx, 'unknown') for idx in y_pred_multiclass_idx]\n",
    "    \n",
    "    # Classes reais para o relat√≥rio\n",
    "    true_labels_list = list(loaded_label_map.values())\n",
    "    \n",
    "    print(classification_report(y_test_true_fraud_labels, y_pred_multiclass_labels, labels=true_labels_list))\n",
    "    print(\"Matriz de Confus√£o (Multiclasse):\")\n",
    "    print(confusion_matrix(y_test_true_fraud_labels, y_pred_multiclass_labels, labels=true_labels_list))\n",
    "else:\n",
    "    print(\"N√£o foram encontradas fraudes verdadeiras no conjunto de teste para avaliar o modelo multiclasse.\")\n",
    "\n",
    "print(\"\\nC√©lula 8 conclu√≠da. Avalia√ß√£o final completa.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Treinamento",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
