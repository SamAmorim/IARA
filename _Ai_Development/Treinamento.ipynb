{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "895c6e5e-0398-4c09-8cf5-94d572c09fb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Configura√ß√µes e Instala√ß√£o de pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18d0ce98-7b47-438d-8b5b-ef80c27a8879",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.4.2 tensorflow==2.16.1 scikeras==0.13.0 joblib\n",
    "\n",
    "print(\"Depend√™ncias de MLOps instaladas/verificadas.\")\n",
    "print(\"Vers√µes compat√≠veis: scikit-learn==1.4.2, tensorflow==2.16.1, scikeras==0.13.0\")\n",
    "print(\"Reiniciando o kernel Python agora para carregar as novas bibliotecas...\")\n",
    "\n",
    "\n",
    "# Esta fun√ß√£o nativa do Databricks reinicia o kernel Python.\n",
    "# Todas as vari√°veis ser√£o limpas, o que √© o comportamento esperado \n",
    "# ao instalar bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e4b680-1fa5-49b6-82c4-2048826e8894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7373f92d-566b-4027-8f1f-f97baf2757de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a3a7d3-5a0a-4818-a6fc-f0870a94cf8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "# REFATORA√á√ÉO: Imports espec√≠ficos do MLflow necess√°rios para salvar e carregar\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc \n",
    "# FIM DA REFATORA√á√ÉO\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from mlflow.models.signature import infer_signature\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Configura√ß√µes Globais ---\n",
    "# A View de features que j√° existe e ser√° lida\n",
    "VIEW_NAME = \"transacoes_db.feature_store.in_live_features\"\n",
    "\n",
    "# --- MUDAN√áA PRINCIPAL AQUI ---\n",
    "# Diret√≥rio em seu Volume do Unity Catalog para salvar os artefatos\n",
    "# (Assumindo que voc√™ queira manter uma subpasta 'pix_fraud' dentro do volume)\n",
    "MODEL_ARTIFACTS_DIR = \"/Volumes/transacoes_db/copper/files/pix_fraud/production_artifacts/\"\n",
    "# --- FIM DA MUDAN√áA ---\n",
    "\n",
    "# Semente para reprodutibilidade\n",
    "SEED = 42\n",
    "\n",
    "# --- Configura√ß√µes de Ambiente ---\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Garantir que o diret√≥rio de artefatos exista no Volume\n",
    "os.makedirs(MODEL_ARTIFACTS_DIR, exist_ok=True)\n",
    "print(f\"Diret√≥rio de artefatos garantido: {MODEL_ARTIFACTS_DIR}\")\n",
    "\n",
    "# --- Sementes de Aleatoriedade ---\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "\n",
    "# Inicializar SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f84d8574-7052-4089-9393-ea6ee4d55c09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "/* CONTEXTO DA VIEW: transacoes_db.feature_store.in_live_features\n",
    "(Esta c√©lula %sql √© apenas para documenta√ß√£o, a view j√° existe)\n",
    "\n",
    "Esta view agrega dados transacionais com perfis e features de janela temporal.\n",
    "*\n",
    "SELECT\n",
    "  -- Colunas da transa√ß√£o\n",
    "  ft.valor AS valor_transacao,\n",
    "  ft.data AS data_transacao,\n",
    "  ft.id_conta_origem AS id_conta_pagador,\n",
    "  ft.id_conta_destino AS id_conta_recebedor,\n",
    "  ft.id_tipo_iniciacao_pix AS tipo_iniciacao_pix_id,\n",
    "  ft.id_finalidade_pix AS finalidade_pix_id,\n",
    "  \n",
    "  -- Targets (R√≥tulos)\n",
    "  ft.is_fraud AS transacao_fraudulenta, -- (Bin√°rio: 0 ou 1)\n",
    "  ft.fraud_type AS tipo_fraude,         -- (Multiclasse: 'scam', 'roubo', etc.)\n",
    "\n",
    "  -- Perfis (Pagador e Recebedor)\n",
    "  conta_orig.saldo AS pagador_saldo,\n",
    "  conta_orig.aberta_em AS pagador_conta_aberta_em,\n",
    "  conta_orig.id_tipo_conta AS pagador_tipo_conta_id,\n",
    "  cliente_orig.id_natureza AS pagador_natureza_id,\n",
    "  cliente_orig.nascido_em AS pagador_data_nascimento,\n",
    "  conta_dest.saldo AS recebedor_saldo,\n",
    "  conta_dest.aberta_em AS recebedor_conta_aberta_em,\n",
    "  conta_dest.id_tipo_conta AS recebedor_tipo_conta_id,\n",
    "  cliente_dest.id_natureza AS recebedor_natureza_id,\n",
    "  cliente_dest.nascido_em AS recebedor_data_nascimento,\n",
    "\n",
    "  -- Features de Tempo Real (Window Functions)\n",
    "  ft.pagador_txs_ultimas_24h,\n",
    "  ft.pagador_valor_ultimas_24h,\n",
    "  ft.recebedor_txs_ultima_1h,\n",
    "  ft.recebedor_valor_ultima_1h,\n",
    "  ft.pagador_segundos_desde_ultima_tx\n",
    "FROM\n",
    "  transacoes_db.feature_store.in_live_features AS ft\n",
    "... (JOINS com tabelas copper de perfis) ...\n",
    "limit 1 */\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a9f650d-c319-4df0-a224-c8437d25d86b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Carregamento e Pre-Processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "651ce2fe-40e6-4f04-8086-3e583b471ac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Carregando dados da view: {VIEW_NAME}...\")\n",
    "# 1. Carregar dados do Delta Lake (Spark)\n",
    "df_spark = spark.read.table(VIEW_NAME)\n",
    "\n",
    "# 2. Converter para Pandas\n",
    "# Assumindo que o dataset cabe na mem√≥ria do driver para treinamento com Sklearn/Keras\n",
    "df_pandas = df_spark.toPandas()\n",
    "print(f\"Dados carregados. Total de {len(df_pandas)} registros.\")\n",
    "\n",
    "# 3. Separar Features (X) e Targets (y)\n",
    "# IDs n√£o s√£o features para o modelo\n",
    "features_to_drop = ['transacao_fraudulenta', 'tipo_fraude', 'id_conta_pagador', 'id_conta_recebedor']\n",
    "X = df_pandas.drop(columns=features_to_drop)\n",
    "y_binary = df_pandas['transacao_fraudulenta']\n",
    "y_multiclass = df_pandas['tipo_fraude'] # Este ainda √© string ('scam', 'legitimo', etc.)\n",
    "\n",
    "# 4. Divis√£o em Treino (70%), Valida√ß√£o (15%) e Teste (15%)\n",
    "# Primeiro, 70% treino e 30% tempor√°rio (para val/teste)\n",
    "X_train, X_temp, y_train_binary, y_temp_binary, y_train_multiclass, y_temp_multiclass = train_test_split(\n",
    "    X, y_binary, y_multiclass, \n",
    "    test_size=0.30, \n",
    "    random_state=SEED, \n",
    "    stratify=y_binary # Garantir propor√ß√£o de fraude\n",
    ")\n",
    "\n",
    "# Segundo, dividir os 30% tempor√°rios em 15% valida√ß√£o e 15% teste (50% de 30% = 15%)\n",
    "X_val, X_test, y_val_binary, y_test_binary, y_val_multiclass, y_test_multiclass = train_test_split(\n",
    "    X_temp, y_temp_binary, y_temp_multiclass, \n",
    "    test_size=0.50, # 50% do temp (que era 30% do total)\n",
    "    random_state=SEED, \n",
    "    stratify=y_temp_binary # Garantir propor√ß√£o de fraude\n",
    ")\n",
    "\n",
    "# Verificar as propor√ß√µes\n",
    "print(\"--- Divis√£o dos Dados ---\")\n",
    "print(f\"Treino:   {X_train.shape[0]} amostras\")\n",
    "print(f\"Valida√ß√£o: {X_val.shape[0]} amostras\")\n",
    "print(f\"Teste:    {X_test.shape[0]} amostras\")\n",
    "\n",
    "print(\"\\n--- Propor√ß√£o de Fraude (Bin√°rio) ---\")\n",
    "print(f\"Treino:    {y_train_binary.value_counts(normalize=True)[1]:.4f}\")\n",
    "print(f\"Valida√ß√£o: {y_val_binary.value_counts(normalize=True)[1]:.4f}\")\n",
    "print(f\"Teste:     {y_test_binary.value_counts(normalize=True)[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02db5588-2518-4c7d-ac28-c26b59a1af0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# An√°lise Explorat√≥ria de Dados (EDA)\n",
    "\n",
    "Analisando a distribui√ß√£o dos dados, valores nulos e correla√ß√µes antes do pr√©-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38bbc492-9641-4601-89ad-5accc0a0111f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Verificar valores nulos (usando o df_pandas completo)\n",
    "print(\"--- Contagem de Valores Nulos por Coluna ---\")\n",
    "null_counts = df_pandas.isnull().sum()\n",
    "# Mostrar apenas colunas que de fato t√™m valores nulos\n",
    "print(null_counts[null_counts > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f86551-6628-4be1-a42a-bf8d7d531660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lista de features num√©ricas (da sua C√©lula 10)\n",
    "numeric_features_eda = [\n",
    "    'valor_transacao', 'pagador_saldo', 'recebedor_saldo',\n",
    "    'pagador_txs_ultimas_24h', 'pagador_valor_ultimas_24h',\n",
    "    'recebedor_txs_ultima_1h', 'recebedor_valor_ultima_1h',\n",
    "    'pagador_segundos_desde_ultima_tx',\n",
    "    'primeira_interacao', 'pagador_interacoes_com_recebedor',\n",
    "    'recebedor_num_pagadores_unicos_24h',\n",
    "    'recebedor_idade_conta_dias', 'pagador_idade_conta_dias',\n",
    "    'valor_vs_media_pagador_30d', 'valor_vs_saldo_pagador'\n",
    "]\n",
    "\n",
    "print(\"--- Distribui√ß√£o das Features Num√©ricas (Log Scale) ---\")\n",
    "# Usar X_train garante que estamos analisando apenas os dados de treino\n",
    "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_features_eda):\n",
    "    if col in X_train.columns:\n",
    "        # Plotar usando os dados de treino\n",
    "        sns.histplot(X_train[col], ax=axes[i], kde=True, log_scale=True)\n",
    "        axes[i].set_title(f'Distribui√ß√£o (Treino) de {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c919420d-fe0c-4965-b05f-25183fe88f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Mapa de Calor de Correla√ß√£o (Dados de Treino) ---\")\n",
    "\n",
    "# Calcular correla√ß√£o apenas nas features num√©ricas + target (usando dados de treino)\n",
    "corr_df = X_train[numeric_features_eda].copy()\n",
    "corr_df['transacao_fraudulenta'] = y_train_binary\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_df.corr(), annot=True, fmt='.2f', cmap='coolwarm', annot_kws={\"size\": 8})\n",
    "plt.title('Mapa de Calor de Correla√ß√£o (Features Num√©ricas vs Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de414df-e05b-431c-91e3-89a98db58cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Fun√ß√µes para Treinamento do Modelo / Defini√ß√£o de Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3fcf78a-4e2a-4c11-8727-37f99e4722a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Imports Necess√°rios para esta C√©lula ---\n",
    "# (Voc√™ pode adicion√°-los √† C√©lula 5 do seu notebook se preferir)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "# ------------------------------------------------\n",
    "\n",
    "# --- [NOVA CLASSE] Custom Transformer de Data/Hora ---\n",
    "# Esta classe substitui a fun√ß√£o 'feature_engineer_datetimes'\n",
    "# O Pickle/Joblib salva classes de forma muito mais est√°vel\n",
    "class DatetimeFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer customizado do Sklearn para engenharia de features de data/hora.\n",
    "    Substitui a fun√ß√£o 'feature_engineer_datetimes'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # O fit n√£o faz nada, apenas retorna a pr√≥pria classe\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    # O transform cont√©m a sua l√≥gica original\n",
    "    def transform(self, X, y=None) -> pd.DataFrame:\n",
    "        # Criar c√≥pia para evitar SettingWithCopyWarning\n",
    "        # Nota: X ser√° o DataFrame filtrado com as colunas de 'datetime_features'\n",
    "        df = X.copy()\n",
    "        \n",
    "        # DataFrame de sa√≠da\n",
    "        df_out = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        # Timestamp atual para c√°lculos de idade\n",
    "        now = datetime.now()\n",
    "\n",
    "        # 1. 'data_transacao'\n",
    "        dt_tx = pd.to_datetime(df['data_transacao'])\n",
    "        df_out['tx_hora_do_dia'] = dt_tx.dt.hour\n",
    "        df_out['tx_dia_da_semana'] = dt_tx.dt.dayofweek\n",
    "        df_out['tx_mes'] = dt_tx.dt.month\n",
    "\n",
    "        # 2. Idade das Contas (em dias)\n",
    "        # (Removida a 'pagador_idade_conta_dias' pois ela j√° vem do SQL na sua lista 'numeric_features')\n",
    "        df_out['recebedor_idade_conta_dias'] = (now - pd.to_datetime(df['recebedor_conta_aberta_em'])).dt.days\n",
    "        \n",
    "        # 3. Idade dos Clientes (em anos)\n",
    "        df_out['pagador_idade_anos'] = ((now - pd.to_datetime(df['pagador_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "        df_out['recebedor_idade_anos'] = ((now - pd.to_datetime(df['recebedor_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "\n",
    "        # Lidar com poss√≠veis nulos que podem ter sido gerados (ex: datas inv√°lidas)\n",
    "        df_out = df_out.fillna(0)\n",
    "        \n",
    "        return df_out\n",
    "# --- Fim da Classe ---\n",
    "\n",
    "\n",
    "# --- Defini√ß√£o das Listas de Colunas ---\n",
    "# (Sem altera√ß√£o, copiadas da sua c√©lula original)\n",
    "numeric_features = [\n",
    "    'valor_transacao', 'pagador_saldo', 'recebedor_saldo',\n",
    "    'pagador_txs_ultimas_24h', 'pagador_valor_ultimas_24h',\n",
    "    'recebedor_txs_ultima_1h', 'recebedor_valor_ultima_1h',\n",
    "    'pagador_segundos_desde_ultima_tx', 'primeira_interacao',\n",
    "    'pagador_interacoes_com_recebedor', 'recebedor_num_pagadores_unicos_24h',\n",
    "    'recebedor_idade_conta_dias', 'pagador_idade_conta_dias',\n",
    "    'valor_vs_media_pagador_30d', 'valor_vs_saldo_pagador'\n",
    "]\n",
    "categorical_features = [\n",
    "    'tipo_iniciacao_pix_id', 'finalidade_pix_id', \n",
    "    'pagador_tipo_conta_id', 'pagador_natureza_id',\n",
    "    'recebedor_tipo_conta_id', 'recebedor_natureza_id'\n",
    "]\n",
    "datetime_features = [\n",
    "    'data_transacao', 'pagador_conta_aberta_em', \n",
    "    'pagador_data_nascimento', 'recebedor_conta_aberta_em', \n",
    "    'recebedor_data_nascimento'\n",
    "]\n",
    "\n",
    "\n",
    "# --- Cria√ß√£o dos Pipelines de Transforma√ß√£o ---\n",
    "# (Sem altera√ß√£o em numeric e categorical)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# --- MUDAN√áA CR√çTICA AQUI ---\n",
    "# Trocamos o FunctionTransformer(feature_engineer_datetimes)\n",
    "# pela nova classe DatetimeFeatureEngineer()\n",
    "datetime_transformer = Pipeline(steps=[\n",
    "    ('feature_eng', DatetimeFeatureEngineer()), # <-- MUDAN√áA\n",
    "    ('scaler', StandardScaler()) # Escalonar as features de data/hora criadas\n",
    "])\n",
    "# --- FIM DA MUDAN√áA ---\n",
    "\n",
    "# --- Montagem do ColumnTransformer (Pr√©-processador) ---\n",
    "# (Sem altera√ß√£o)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('date', datetime_transformer, datetime_features)\n",
    "    ],\n",
    "    remainder='drop' # Ignorar colunas n√£o listadas (ex: IDs)\n",
    ")\n",
    "\n",
    "print(\"Pipeline de pr√©-processamento 'preprocessor' definido com sucesso (usando Classe Customizada).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a137f5e-6ce7-4116-959f-9befaef0ba81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Fun√ß√µes de Cria√ß√£o de modelo Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864f0950-4ec2-4266-ad11-cf31ec91406e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Fun√ß√£o Factory para Modelo Bin√°rio ---\n",
    "def build_binary_model(meta):\n",
    "    \"\"\"Constr√≥i o modelo bin√°rio para o KerasClassifier.\"\"\"\n",
    "    # scikeras injeta n_features_in_ automaticamente\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    \n",
    "    # Garantir que a semente do TF seja definida dentro da fun√ß√£o\n",
    "    # para reprodutibilidade quando o KerasClassifier for clonado\n",
    "    tf.random.set_seed(SEED) \n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid') # Sa√≠da sigmoide para bin√°rio\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['AUC', tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# --- Fun√ß√£o Factory para Modelo Multiclasse ---\n",
    "def build_multiclass_model(meta):\n",
    "    \"\"\"Constr√≥i o modelo multiclasse para o KerasClassifier.\"\"\"\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    # scikeras injeta o n√∫mero de classes √∫nicas (ex: 3 tipos de fraude)\n",
    "    n_classes_out = meta[\"n_classes_\"]\n",
    "    \n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(n_classes_out, activation='softmax') # Sa√≠da softmax\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', # Usar sparse pois os labels s√£o inteiros (0, 1, 2)\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Fun√ß√µes de constru√ß√£o de modelo Keras ('build_binary_model', 'build_multiclass_model') definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cfe2910-6427-4501-b242-264bcd9ab18e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Treinamento do modelo Binario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0760c1b2-4b7a-4871-9129-3e282dfe1441",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Iniciando prepara√ß√£o para o Modelo 1 (Bin√°rio)...\")\n",
    "\n",
    "# 1. Definir o nome da Run do MLflow\n",
    "mlflow_run_name = \"Fraud_Detection_Binary\"\n",
    "\n",
    "# 2. Callback de Early Stopping\n",
    "early_stopping_binary = EarlyStopping(\n",
    "    monitor='val_loss', # Acompanhar a perda na valida√ß√£o\n",
    "    patience=5,         # Parar ap√≥s 5 √©pocas sem melhoria\n",
    "    restore_best_weights=True, # Restaurar os melhores pesos no final\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. Iniciar a Run do MLflow\n",
    "with mlflow.start_run(run_name=mlflow_run_name) as run_binary:\n",
    "    print(f\"Iniciando Run MLflow: {run_binary.info.run_id}\")\n",
    "    \n",
    "    # 4. Definir o KerasClassifier (Scikeras)\n",
    "    # CORRE√á√ÉO: 'build_fn' foi depreciado para 'model'\n",
    "    keras_binary_model = KerasClassifier(\n",
    "        model=build_binary_model, # <-- MUDAN√áA AQUI\n",
    "        epochs=50, \n",
    "        batch_size=256, \n",
    "        verbose=1, \n",
    "        random_state=SEED\n",
    "    )\n",
    "    # --- FIM DA CORRE√á√ÉO ---\n",
    "\n",
    "    # 5. Criar o Pipeline Sklearn completo\n",
    "    pipeline_binary = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', keras_binary_model)\n",
    "    ])\n",
    "    \n",
    "    # 6. Pr√©-processar dados de valida√ß√£o\n",
    "    print(\"Pr√©-ajustando o processador para transformar dados de valida√ß√£o...\")\n",
    "    # Usamos clone() para n√£o \"sujar\" o preprocessor do pipeline antes do .fit()\n",
    "    preprocessor_for_val = clone(preprocessor).fit(X_train)\n",
    "    X_val_processed = preprocessor_for_val.transform(X_val)\n",
    "    print(f\"Dimens√µes dos dados de valida√ß√£o processados: {X_val_processed.shape}\")\n",
    "    \n",
    "    # 7. Treinar o pipeline\n",
    "    print(\"Iniciando treinamento do pipeline bin√°rio...\")\n",
    "    pipeline_binary.fit(\n",
    "        X_train, y_train_binary, \n",
    "        model__validation_data=(X_val_processed, y_val_binary), # Passar dados de valida√ß√£o para o Keras\n",
    "        model__callbacks=[early_stopping_binary] # Passar o callback\n",
    "    )\n",
    "    print(\"Treinamento bin√°rio conclu√≠do.\")\n",
    "\n",
    "    # 8. Avaliar no set de teste\n",
    "    y_pred_binary = pipeline_binary.predict(X_test)\n",
    "    y_pred_proba_binary = pipeline_binary.predict_proba(X_test)[:, 1] # Probabilidade da classe 1\n",
    "\n",
    "    # M√©tricas\n",
    "    recall = recall_score(y_test_binary, y_pred_binary)\n",
    "    precision = precision_score(y_test_binary, y_pred_binary)\n",
    "    f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "    roc_auc = roc_auc_score(y_test_binary, y_pred_proba_binary)\n",
    "    \n",
    "    # Logar M√©tricas no MLflow\n",
    "    mlflow.log_metrics({\n",
    "        \"test_recall\": recall,\n",
    "        \"test_precision\": precision,\n",
    "        \"test_f1\": f1,\n",
    "        \"test_roc_auc\": roc_auc\n",
    "    })\n",
    "    \n",
    "    print(\"\\n--- M√©tricas de Teste (Bin√°rio) ---\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_test_binary, y_pred_binary))\n",
    "\n",
    "    # 8. Salvamento Cr√≠tico do Artefato (usar√° o caminho do Volume)\n",
    "    binary_pipeline_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_binary_pipeline\") # Salvar como pasta\n",
    "    \n",
    "    # --- REFATORA√á√ÉO ---\n",
    "    # Substituir joblib.dump por mlflow.sklearn.save_model\n",
    "    # Isso garante que as fun√ß√µes build_fn e classes custom (DatetimeFeatures) sejam salvas\n",
    "    print(f\"Salvando pipeline bin√°rio no formato MLflow em: {binary_pipeline_path}...\")\n",
    "    mlflow.sklearn.save_model(\n",
    "        pipeline_binary, \n",
    "        binary_pipeline_path,\n",
    "        # Adicionar a assinatura ajuda o MLflow a entender as entradas/sa√≠das\n",
    "        signature=infer_signature(X_train, pipeline_binary.predict(X_train)),\n",
    "        input_example=X_train.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    print(f\"Pipeline bin√°rio salvo com sucesso em: {binary_pipeline_path}\")\n",
    "    # --- FIM DA REFATORA√á√ÉO ---\n",
    "\n",
    "    # 9. Logar no MLflow (modelo e artefato)\n",
    "    # Logar o modelo (que j√° est√° salvo) como \"modelo\" dentro da run\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_binary, \n",
    "        \"binary_model\", \n",
    "        signature=infer_signature(X_train, pipeline_binary.predict(X_train)),\n",
    "        input_example=X_train.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    # Logar o caminho do volume como um artefato (opcional, mas bom para rastreio)\n",
    "    mlflow.log_artifact(binary_pipeline_path)\n",
    "\n",
    "print(\"C√©lula 20 conclu√≠da.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b006f7c-0f5c-40f8-95ad-766550343e96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analise Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50bfc191-a8d0-4f1b-920f-5154c7bc38c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "print(\"Gerando Curva ROC para o Modelo Bin√°rio...\")\n",
    "\n",
    "# Esta c√©lula depende das vari√°veis 'y_test_binary' (da C√©lula 8) e\n",
    "# 'y_pred_binary_proba' (calculada na C√©lula 14).\n",
    "# Certifique-se de que a C√©lula 14 foi executada.\n",
    "\n",
    "try:\n",
    "    # Calcular a curva\n",
    "    fpr_binary, tpr_binary, _ = roc_curve(y_test_binary, y_pred_binary_proba)\n",
    "    roc_auc_binary = auc(fpr_binary, tpr_binary)\n",
    "\n",
    "    # Plotar\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr_binary, tpr_binary, color='darkorange', lw=2,\n",
    "             label=f'Curva ROC Bin√°ria (AUC = {roc_auc_binary:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # Linha de 45 graus\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "    plt.title('Curva ROC - Modelo Bin√°rio (Fraude vs. N√£o Fraude)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Erro: Vari√°vel n√£o encontrada. {e}\")\n",
    "    print(\"Por favor, certifique-se de que a C√©lula 14 (treinamento bin√°rio) foi executada com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f46635-8b74-4fa3-85fa-cf79f6b75730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Curva Precision-Recall e An√°lise de Limiar (Modelo Bin√°rio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ffb2c7f-9a5a-418f-b66c-140c3013e4c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "print(\"--- Curva Precision-Recall (Modelo Bin√°rio) ---\")\n",
    "\n",
    "# Calcular precision e recall para diferentes limiares\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_binary, y_pred_binary_proba)\n",
    "# Calcular a √°rea sob a curva PR (AP)\n",
    "ap_score = average_precision_score(y_test_binary, y_pred_binary_proba)\n",
    "\n",
    "# Encontrar o limiar que maximiza o F1-Score\n",
    "# (evitar divis√£o por zero)\n",
    "f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_f1_idx]\n",
    "best_f1 = f1_scores[best_f1_idx]\n",
    "\n",
    "print(f\"Melhor F1-Score: {best_f1:.4f}\")\n",
    "print(f\"Limiar (Threshold) √≥timo: {best_threshold:.4f}\")\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Curva PR (AP = {ap_score:.4f})')\n",
    "plt.scatter(recall[best_f1_idx], precision[best_f1_idx], marker='o', color='red', s=100, \n",
    "            label=f'Melhor F1 (Limiar={best_threshold:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall - Modelo Bin√°rio')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de388077-27e9-45db-ac9d-0efe2fb7e83c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### An√°lise de Erros (Modelo Bin√°rio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bed9090-6026-407b-a78f-52d4804ae6ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 'y_pred_binary' foi calculado na C√©lula 14\n",
    "# 'X_test' e 'y_test_binary' foram criados na C√©lula 8\n",
    "\n",
    "# Criar m√°scaras de erro\n",
    "fn_mask = (y_test_binary == 1) & (y_pred_binary == 0) # Falsos Negativos (Fraudes Perdidas)\n",
    "fp_mask = (y_test_binary == 0) & (y_pred_binary == 1) # Falsos Positivos (Alertas Falsos)\n",
    "\n",
    "# Criar DataFrames de erros\n",
    "df_falsos_negativos = X_test[fn_mask]\n",
    "df_falsos_positivos = X_test[fp_mask]\n",
    "\n",
    "print(f\"--- An√°lise de Falsos Negativos (Fraudes Perdidas) ---\")\n",
    "print(f\"Total de fraudes perdidas: {len(df_falsos_negativos)}\")\n",
    "# Exibir estat√≠sticas das fraudes que o modelo errou\n",
    "if not df_falsos_negativos.empty:\n",
    "    print(df_falsos_negativos[numeric_features_eda].describe())\n",
    "\n",
    "print(f\"\\n--- An√°lise de Falsos Positivos (Alertas Falsos) ---\")\n",
    "print(f\"Total de alertas falsos: {len(df_falsos_positivos)}\")\n",
    "# Exibir estat√≠sticas das transa√ß√µes leg√≠timas que o modelo errou\n",
    "if not df_falsos_positivos.empty:\n",
    "    print(df_falsos_positivos[numeric_features_eda].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fdd78fc-2698-4600-8dad-fb95b9285d8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Import√¢ncia das Features (Explicabilidade do Modelo Bin√°rio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73735125-3c90-48cf-94ee-d0ad555ab3a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# print(\"Calculando Permutation Importance (pode demorar alguns segundos)...\")\n",
    "\n",
    "# # Calcular a import√¢ncia usando o conjunto de valida√ß√£o\n",
    "# result = permutation_importance(\n",
    "#     pipeline_binary, \n",
    "#     X_val, \n",
    "#     y_val_binary, \n",
    "#     n_repeats=10, \n",
    "#     random_state=SEED, \n",
    "#     n_jobs=-1,\n",
    "#     scoring='f1'\n",
    "# )\n",
    "\n",
    "# # Tentar obter os nomes das features do pr√©-processador\n",
    "# preprocessor = pipeline_binary.named_steps['preprocessor']\n",
    "# try:\n",
    "#     feature_names = preprocessor.get_feature_names_out()\n",
    "# except AttributeError:\n",
    "#     # Se algum transformador n√£o suportar, usar os nomes das colunas originais\n",
    "#     feature_names = X_val.columns\n",
    "\n",
    "# # Organizar os resultados\n",
    "# df_importance = pd.DataFrame(\n",
    "#     data={\n",
    "#         'importance_mean': result.importances_mean,\n",
    "#         'importance_std': result.importances_std\n",
    "#     },\n",
    "#     index=feature_names\n",
    "# ).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "# # Exibir o DataFrame de import√¢ncia das features\n",
    "# display(df_importance)\n",
    "\n",
    "# # Plotar as top 20 features\n",
    "# print(\"--- Top 20 Features Mais Importantes (Modelo Bin√°rio) ---\")\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# df_importance.head(20)['importance_mean'].plot(kind='barh')\n",
    "# plt.title('Permutation Feature Importance (Modelo Bin√°rio)')\n",
    "# plt.xlabel('Redu√ß√£o m√©dia no F1-Score')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "58736326-95d8-44a9-b16e-1e70e317a0b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Defini√ß√£o da Fun√ß√£o (J√° ajustada para imprimir resultados)\n",
    "def plot_learning_curve(model, X, y, title=\"Curva de Aprendizado\", \n",
    "                        cv=5, \n",
    "                        train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                        scoring='f1'): # Adicionado 'scoring' como par√¢metro para clareza\n",
    "    \"\"\"\n",
    "    Plota a curva de aprendizado e imprime os scores m√©dios.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Informa quantos treinamentos ser√£o feitos\n",
    "    total_fits = len(train_sizes) * cv\n",
    "    print(f\"Calculando curva de aprendizado... Total de {total_fits} treinamentos.\")\n",
    "\n",
    "    # A fun√ß√£o learning_curve retorna os tamanhos absolutos usados\n",
    "    train_sizes_abs, train_scores, val_scores = learning_curve(\n",
    "        model, X, y, cv=cv, scoring=scoring, n_jobs=-1,\n",
    "        train_sizes=train_sizes, shuffle=True, random_state=42\n",
    "    )\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "\n",
    "    # --- O \"Resultado Direto\" ---\n",
    "    print(\"\\n--- Resultados (M√©dias) ---\")\n",
    "    print(f\"{'Tamanho Treino':<15} | {'F1 Treino':<10} | {'F1 Valida√ß√£o':<10}\")\n",
    "    print(\"-\" * 47)\n",
    "    for i, size in enumerate(train_sizes_abs):\n",
    "        print(f\"{size:<15} | {train_mean[i]:<10.4f} | {val_mean[i]:<10.4f}\")\n",
    "    print(\"---------------------------\\n\")\n",
    "    # -----------------------------\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(train_sizes_abs, train_mean, 'o-', label=\"Treino\", linewidth=2)\n",
    "    plt.plot(train_sizes_abs, val_mean, 'o-', label=\"Valida√ß√£o\", linewidth=2)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel(\"Tamanho do conjunto de treino (N¬∫ de amostras)\")\n",
    "    plt.ylabel(\"F1-Score\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "# --- 2. Defini√ß√£o dos par√¢metros para rodar r√°pido ---\n",
    "cv_rapido = 3\n",
    "tamanhos_rapidos = np.linspace(0.25, 1.0, 3) # 3 pontos (25%, 62.5%, 100%)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71e41169-259d-4501-a127-bfd07ed517c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(\n",
    "#     pipeline_binary, \n",
    "#     X_train, \n",
    "#     y_train_binary, \n",
    "#     title=\"Curva de Aprendizado - Modelo Bin√°rio (R√°pida)\", \n",
    "#     cv=cv_rapido, \n",
    "#     train_sizes=tamanhos_rapidos,\n",
    "#     scoring='f1' # Scoring correto para o bin√°rio\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe769f9b-65a9-4e4f-8bb3-12e6d324c637",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìä COMPARATIVO DE M√âTRICAS ENTRE TREINO E TESTE - MODELO BIN√ÅRIO\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Calcular m√©tricas no treino\n",
    "y_pred_train = pipeline_binary.predict(X_train)\n",
    "y_pred_train_proba = pipeline_binary.predict_proba(X_train)[:, 1]\n",
    "\n",
    "recall_train = float(recall_score(y_train_binary, y_pred_train))\n",
    "precision_train = float(precision_score(y_train_binary, y_pred_train))\n",
    "f1_train = float(f1_score(y_train_binary, y_pred_train))\n",
    "roc_auc_train = float(roc_auc_score(y_train_binary, y_pred_train_proba))\n",
    "\n",
    "# Calcular m√©tricas no teste\n",
    "y_pred_test = pipeline_binary.predict(X_val)\n",
    "y_pred_test_proba = pipeline_binary.predict_proba(X_val)[:, 1]\n",
    "\n",
    "recall = float(recall_score(y_val_binary, y_pred_test))\n",
    "precision = float(precision_score(y_val_binary, y_pred_test))\n",
    "f1 = float(f1_score(y_val_binary, y_pred_test))\n",
    "roc_auc = float(roc_auc_score(y_val_binary, y_pred_test_proba))\n",
    "\n",
    "metrics_data = {\n",
    "    'Conjunto': ['Treino', 'Teste'],\n",
    "    'Recall': [recall_train, recall],\n",
    "    'Precision': [precision_train, precision],\n",
    "    'F1-Score': [f1_train, f1],\n",
    "    'ROC AUC': [roc_auc_train, roc_auc]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "df_metrics_melt = df_metrics.melt(\n",
    "    id_vars='Conjunto',\n",
    "    var_name='M√©trica',\n",
    "    value_name='Valor'\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x='M√©trica',\n",
    "    y='Valor',\n",
    "    hue='Conjunto',\n",
    "    data=df_metrics_melt,\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title('Comparativo de M√©tricas - Treino vs Teste (Modelo Bin√°rio)', fontsize=14)\n",
    "plt.ylim(0.85, 1.0)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b97fdc1-b7e2-4509-ba35-b5f147114087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Crie um DataFrame com os resultados do teste\n",
    "# (Usando as vari√°veis 'y_test_binary' e 'y_pred_binary_proba' do seu script)\n",
    "df_results = pd.DataFrame({\n",
    "    'Probabilidade Prevista': y_pred_binary_proba,\n",
    "    'Classe Real': y_test_binary\n",
    "})\n",
    "\n",
    "# Mapear os valores num√©ricos para r√≥tulos claros (opcional, mas recomendado)\n",
    "df_results['Classe Real'] = df_results['Classe Real'].map({0: 'N√£o Fraude', 1: 'Fraude'})\n",
    "\n",
    "# 2. Gerar o Gr√°fico de Densidade (KDE Plot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(\n",
    "    data=df_results, \n",
    "    x='Probabilidade Prevista', \n",
    "    hue='Classe Real',  # Isso cria uma curva para cada classe\n",
    "    fill=True,          # Preenche a √°rea sob a curva\n",
    "    common_norm=False,  # Garante que cada curva seja normalizada independentemente\n",
    "    palette=['#2ecc71', '#e74c3c'], # Suas cores originais\n",
    "    alpha=0.5           # Transpar√™ncia\n",
    ")\n",
    "\n",
    "plt.title('Distribui√ß√£o das Probabilidades Previstas por Classe Real', fontsize=16)\n",
    "plt.xlabel('Probabilidade Prevista de Fraude', fontsize=12)\n",
    "plt.ylabel('Densidade', fontsize=12)\n",
    "plt.legend(title='Classe Real')\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Adicionar linhas verticais para clareza (opcional)\n",
    "plt.axvline(0.5, color='blue', linestyle='--', label='Threshold (0.5)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98c75f9b-a3f5-4e1d-b33d-2ee8d8e82c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üß© MATRIZ DE CONFUS√ÉO ESTILIZADA - MODELO BIN√ÅRIO\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax, colorbar=False)\n",
    "plt.title('Matriz de Confus√£o - Modelo Bin√°rio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2084ceba-0a09-4674-b687-8d63a962ae30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Treinamento do Modelo Multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70bd302b-7f85-437e-be82-ef2e2c2664b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Iniciando prepara√ß√£o para o Modelo 2 (Multiclasse)...\")\n",
    "\n",
    "# 1. Filtrar dados para incluir apenas transa√ß√µes fraudulentas\n",
    "train_fraud_mask = (y_train_binary == 1)\n",
    "val_fraud_mask = (y_val_binary == 1)\n",
    "test_fraud_mask = (y_test_binary == 1)\n",
    "\n",
    "X_train_fraud = X_train[train_fraud_mask]\n",
    "y_train_multiclass_fraud = y_train_multiclass[train_fraud_mask]\n",
    "\n",
    "X_val_fraud = X_val[val_fraud_mask]\n",
    "y_val_multiclass_fraud = y_val_multiclass[val_fraud_mask]\n",
    "\n",
    "X_test_fraud = X_test[test_fraud_mask]\n",
    "y_test_multiclass_fraud = y_test_multiclass[test_fraud_mask]\n",
    "\n",
    "print(f\"Total de amostras de fraude para treino: {len(X_train_fraud)}\")\n",
    "print(f\"Total de amostras de fraude para valida√ß√£o: {len(X_val_fraud)}\")\n",
    "print(f\"Total de amostras de fraude para teste: {len(X_test_fraud)}\")\n",
    "\n",
    "# 2. Usar LabelEncoder para converter labels string em inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_multiclass_encoded = label_encoder.fit_transform(y_train_multiclass_fraud)\n",
    "y_val_multiclass_encoded = label_encoder.transform(y_val_multiclass_fraud)\n",
    "y_test_multiclass_encoded = label_encoder.transform(y_test_multiclass_fraud)\n",
    "\n",
    "print(f\"Classes de fraude encontradas: {label_encoder.classes_}\")\n",
    "\n",
    "# 3. Salvamento Cr√≠tico (Mapeamento de Labels) (usar√° o caminho do Volume)\n",
    "# Criar mapa {0: 'scam', 1: 'roubo', 2: 'lavagem'}\n",
    "label_map = {i: str(cls) for i, cls in enumerate(label_encoder.classes_)}\n",
    "label_map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "\n",
    "with open(label_map_path, 'w') as f:\n",
    "    json.dump(label_map, f, indent=4)\n",
    "print(f\"Mapa de labels salvo em: {label_map_path}\")\n",
    "\n",
    "# --- Treinamento do Modelo Multiclasse ---\n",
    "\n",
    "# Callback para o modelo multiclasse\n",
    "early_stopping_multi = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Fraud_Type_Classifier\") as run_multiclass:\n",
    "    print(f\"Iniciando Run MLflow: {run_multiclass.info.run_id}\")\n",
    "    \n",
    "\n",
    "    keras_multiclass_model = KerasClassifier(\n",
    "        model=build_multiclass_model, # <-- MUDAN√áA DE 'build_fn' PARA 'model'\n",
    "        epochs=50, \n",
    "        batch_size=128, \n",
    "        verbose=1,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    # --- FIM DA CORRE√á√ÉO ---\n",
    "\n",
    "    # 5. Criar o Pipeline completo\n",
    "    pipeline_multiclass = Pipeline([\n",
    "        ('preprocessor', preprocessor), \n",
    "        ('model', keras_multiclass_model)\n",
    "    ])\n",
    "    \n",
    "    # 6. Pr√©-processar dados de valida√ß√£o (apenas de fraude)\n",
    "    print(\"Pr√©-ajustando o processador (multiclasse) nos dados de treino de fraude...\")\n",
    "    # Usamos clone() para n√£o \"sujar\" o preprocessor do pipeline antes do .fit()\n",
    "    preprocessor_multi_for_val = clone(preprocessor).fit(X_train_fraud)\n",
    "    X_val_fraud_processed = preprocessor_multi_for_val.transform(X_val_fraud)\n",
    "    print(f\"Dimens√µes dos dados de valida√ß√£o (fraude) processados: {X_val_fraud_processed.shape}\")\n",
    "\n",
    "    # 7. Treinar o pipeline (APENAS com dados de fraude)\n",
    "    print(\"Iniciando treinamento do pipeline multiclasse...\")\n",
    "    pipeline_multiclass.fit(\n",
    "        X_train_fraud, y_train_multiclass_encoded, \n",
    "        model__validation_data=(X_val_fraud_processed, y_val_multiclass_encoded), \n",
    "        model__callbacks=[early_stopping_multi]\n",
    "    )\n",
    "    print(\"Treinamento multiclasse conclu√≠do.\")\n",
    "\n",
    "    # 8. Avaliar no set de teste (filtrado)\n",
    "    y_pred_multiclass_encoded = pipeline_multiclass.predict(X_test_fraud)\n",
    "    \n",
    "    print(\"\\n--- M√©tricas de Teste (Multiclasse) ---\")\n",
    "    report_text = classification_report(\n",
    "        y_test_multiclass_encoded, \n",
    "        y_pred_multiclass_encoded, \n",
    "        target_names=label_encoder.classes_\n",
    "    )\n",
    "    print(report_text)\n",
    "    \n",
    "    # Logar m√©tricas\n",
    "    mlflow.log_text(report_text, \"classification_report.txt\")\n",
    "    f1_micro = f1_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='micro')\n",
    "    mlflow.log_metric(\"test_f1_micro\", f1_micro)\n",
    "\n",
    "    # 9. Salvamento Cr√≠tico (usar√° o caminho do Volume)\n",
    "    multiclass_pipeline_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_pipeline\") # Salvar como pasta\n",
    "    \n",
    "    # --- REFATORA√á√ÉO ---\n",
    "    # Substituir joblib.dump por mlflow.sklearn.save_model\n",
    "    print(f\"Salvando pipeline multiclasse no formato MLflow em: {multiclass_pipeline_path}...\")\n",
    "    mlflow.sklearn.save_model(\n",
    "        pipeline_multiclass, \n",
    "        multiclass_pipeline_path,\n",
    "        signature=infer_signature(X_train_fraud, pipeline_multiclass.predict(X_train_fraud)),\n",
    "        input_example=X_train_fraud.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    print(f\"Pipeline multiclasse salvo em: {multiclass_pipeline_path}\")\n",
    "    # --- FIM DA REFATORA√á√ÉO ---\n",
    "\n",
    "    # 10. Logar no MLflow\n",
    "    signature_multi = infer_signature(X_train_fraud, pipeline_multiclass.predict(X_train_fraud))\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline_multiclass, \n",
    "        \"multiclass_model\", \n",
    "        signature=signature_multi,\n",
    "        input_example=X_train_fraud.head(5).to_dict(orient='records')\n",
    "    )\n",
    "    mlflow.log_artifact(multiclass_pipeline_path)\n",
    "    mlflow.log_artifact(label_map_path) # Importante logar o mapa tamb√©m\n",
    "\n",
    "print(\"C√©lula 27 conclu√≠da.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755e210a-e23f-4dde-a984-14ba1dbe57e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Analise Visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4c3dc8e-bd2f-4085-ae8f-6eccf5d2670b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Curva Precision-Recall e An√°lise de Limiar (Modelo Bin√°rio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d96ea473-eb7f-4ef7-b084-2f8d0774ceb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f434d19c-14b4-4d73-8a0c-f8983d60716e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "\n",
    "print(\"Gerando Curva ROC para o Modelo Multiclasse (One-vs-Rest)...\")\n",
    "\n",
    "# Esta c√©lula depende das vari√°veis da C√©lula 22:\n",
    "# 'pipeline_multiclass', 'X_test_fraud', 'y_test_multiclass_encoded' e 'label_encoder'.\n",
    "# Certifique-se de que a C√©lula 22 foi executada.\n",
    "\n",
    "try:\n",
    "    # Calcular probabilidades para o conjunto de teste de fraude\n",
    "    y_pred_multiclass_proba = pipeline_multiclass.predict_proba(X_test_fraud)\n",
    "    \n",
    "    # Obter classes do label_encoder\n",
    "    classes = label_encoder.classes_\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    # Binarizar os labels verdadeiros (y_test_multiclass_encoded)\n",
    "    y_test_binarized = label_binarize(y_test_multiclass_encoded, classes=list(range(n_classes)))\n",
    "\n",
    "    # Dicion√°rios para armazenar fpr, tpr e auc\n",
    "    fpr_multi = dict()\n",
    "    tpr_multi = dict()\n",
    "    roc_auc_multi = dict()\n",
    "\n",
    "    # Calcular ROC para cada classe\n",
    "    for i in range(n_classes):\n",
    "        fpr_multi[i], tpr_multi[i], _ = roc_curve(y_test_binarized[:, i], y_pred_multiclass_proba[:, i])\n",
    "        roc_auc_multi[i] = auc(fpr_multi[i], tpr_multi[i])\n",
    "\n",
    "    # Plotar o gr√°fico\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    \n",
    "    # Definir um ciclo de cores\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple'])\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr_multi[i], tpr_multi[i], color=color, lw=2,\n",
    "                 label=f'Classe: {classes[i]} (AUC = {roc_auc_multi[i]:.4f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2) # Linha pontilhada de 45 graus\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "    plt.title('Curva ROC One-vs-Rest (OvR) - Modelo Multiclasse')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Erro: Vari√°vel n√£o encontrada. {e}\")\n",
    "    print(\"Por favor, certifique-se de que a C√©lula 22 (treinamento multiclasse) foi executada com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de368e1-6d0f-4140-aa9b-6c7272903568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# plot_learning_curve(\n",
    "#     pipeline_multiclass, \n",
    "#     X_train, \n",
    "#     y_train_binary, \n",
    "#     title=\"urva de Aprendizado - Modelo Multiclasse\", \n",
    "#     cv=cv_rapido, \n",
    "#     train_sizes=tamanhos_rapidos\n",
    "#     #scoring='f1' # Scoring correto para o bin√°rio\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c86138d8-7efa-4ad8-a344-267d18ccb01b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìä COMPARATIVO DE M√âTRICAS ENTRE TREINO E TESTE - MODELO MULTICLASSE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# Previs√µes no treino\n",
    "y_pred_train_multiclass = pipeline_multiclass.predict(X_train_fraud)\n",
    "\n",
    "# M√©tricas no treino\n",
    "recall_train = recall_score(y_train_multiclass_encoded, y_pred_train_multiclass, average='macro')\n",
    "precision_train = precision_score(y_train_multiclass_encoded, y_pred_train_multiclass, average='macro')\n",
    "f1_train = f1_score(y_train_multiclass_encoded, y_pred_train_multiclass, average='macro')\n",
    "\n",
    "# M√©tricas no teste (usando vari√°veis j√° calculadas)\n",
    "recall_test = recall_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='macro')\n",
    "precision_test = precision_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='macro')\n",
    "f1_test = f1_score(y_test_multiclass_encoded, y_pred_multiclass_encoded, average='macro')\n",
    "\n",
    "metrics_data = {\n",
    "    'Conjunto': ['Treino', 'Teste'],\n",
    "    'Recall (Macro)': [recall_train, recall_test],\n",
    "    'Precision (Macro)': [precision_train, precision_test],\n",
    "    'F1-Score (Macro)': [f1_train, f1_test]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "df_metrics_melt = df_metrics.melt(id_vars='Conjunto', var_name='M√©trica', value_name='Valor')\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(x='M√©trica', y='Valor', hue='Conjunto', data=df_metrics_melt, palette='mako')\n",
    "plt.title('Comparativo de M√©tricas - Treino vs Teste (Modelo Multiclasse)', fontsize=14)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b75f2d2-1947-4544-8028-cc3a7f8063cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üìà DISPERS√ÉO DAS PREDI√á√ïES POR CLASSE - MODELO MULTICLASSE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduz dimensionalidade para 2D para visualiza√ß√£o\n",
    "X_test_fraud_transformed = pipeline_multiclass.named_steps['preprocessor'].transform(X_test_fraud)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_2d = pca.fit_transform(X_test_fraud_transformed)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=X_2d[:,0], y=X_2d[:,1], hue=[label_encoder.classes_[i] for i in y_pred_multiclass_encoded],\n",
    "                palette='tab10', alpha=0.7)\n",
    "plt.title('Dispers√£o das Predi√ß√µes por Tipo de Fraude (PCA 2D)', fontsize=14)\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "plt.legend(title='Classe Prevista', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c0d4a12-d993-416e-ae9e-41c803342187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### An√°lise Multiclasse: Matriz de Confus√£o (Visual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbe63022-f156-4443-bcd4-b59a1720ef15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# üß© MATRIZ DE CONFUS√ÉO - MODELO MULTICLASSE\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm_multi = confusion_matrix(y_test_multiclass_encoded, y_pred_multiclass_encoded)\n",
    "fig, ax = plt.subplots(figsize=(8,7))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_multi, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap='Purples', ax=ax, colorbar=False)\n",
    "plt.title('Matriz de Confus√£o - Modelo Multiclasse')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ae8faa-7939-4bbe-b55f-295db5204776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### An√°lise Multiclasse: Import√¢ncia das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55087635-bc3f-4c8d-b576-ab84b31b7c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# print(\"Calculando Permutation Importance (Multiclasse)...\")\n",
    "\n",
    "# try:\n",
    "#     # Usar o set de valida√ß√£o de fraudes (X_val_fraud) para a import√¢ncia\n",
    "#     # 'pipeline_multiclass' foi treinado na C√©lula 22\n",
    "#     # 'X_val_fraud' e 'y_val_multiclass_encoded' foram criados na C√©lula 22\n",
    "    \n",
    "#     # Calcular a import√¢ncia\n",
    "#     result_multi = permutation_importance(\n",
    "#         pipeline_multiclass, \n",
    "#         X_val_fraud, \n",
    "#         y_val_multiclass_encoded, \n",
    "#         n_repeats=10, \n",
    "#         random_state=SEED, \n",
    "#         n_jobs=-1,\n",
    "#         scoring='f1_macro' # Usar 'f1_macro' como m√©trica de impacto\n",
    "#     )\n",
    "\n",
    "#     # Obter nomes das features (reutilizando o 'temp_preprocessor' da an√°lise bin√°ria, \n",
    "#     # ou criando um novo se necess√°rio)\n",
    "#     try:\n",
    "#         feature_names\n",
    "#     except NameError:\n",
    "#         # Criar nomes de features se n√£o existirem\n",
    "#         temp_preprocessor = clone(preprocessor).fit(X_train) \n",
    "#         feature_names = temp_preprocessor.get_feature_names_out()\n",
    "\n",
    "\n",
    "#     # Organizar os resultados\n",
    "#     df_importance_multi = pd.DataFrame(\n",
    "#         data={'importance_mean': result_multi.importances_mean, 'importance_std': result_multi.importances_std},\n",
    "#         index=feature_names\n",
    "#     ).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "#     # Plotar as top 20 features\n",
    "#     print(\"--- Top 20 Features Mais Importantes (Modelo Multiclasse) ---\")\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     df_importance_multi.head(20)['importance_mean'].plot(kind='barh')\n",
    "#     plt.title('Permutation Feature Importance (Modelo Multiclasse)')\n",
    "#     plt.xlabel('Redu√ß√£o m√©dia no F1-Score (Macro)')\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.show()\n",
    "\n",
    "# except NameError as e:\n",
    "#     print(f\"Erro: Vari√°vel n√£o encontrada. {e}\")\n",
    "#     print(\"Certifique-se de que a C√©lula 22 foi executada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02670d65-9da9-4d4e-a604-4fc99fb0cb79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# # ====================================================================================\n",
    "# # ATEN√á√ÉO: Se as vari√°veis abaixo N√ÉO EXISTIREM, rode a C√©lula 8 novamente.\n",
    "# # - y_test_true_fraud_labels: Labels verdadeiros (ex: ['scam', 'roubo', 'scam'])\n",
    "# # - y_pred_multiclass_labels: Labels previstos\n",
    "# # - label_encoder (ou o mapa de labels carregado): Para as classes.\n",
    "# # ====================================================================================\n",
    "\n",
    "# # 1. Tenta carregar o mapa de labels (se a c√©lula anterior n√£o o fez)\n",
    "# try:\n",
    "#     # Ajuste o caminho conforme o seu ambiente (Ex: /dbfs/mnt/artifacts/fraud_type_label_map.json)\n",
    "#     label_map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "#     with open(label_map_path, 'r') as f:\n",
    "#         loaded_label_map = json.load(f)\n",
    "#     class_names = list(loaded_label_map.values())\n",
    "# except (FileNotFoundError, NameError):\n",
    "#     # Se o mapa de labels n√£o estiver dispon√≠vel ou a vari√°vel n√£o existir, usa as classes do relat√≥rio\n",
    "#     print(\"Aviso: N√£o foi poss√≠vel carregar o mapa de labels. Tentando inferir nomes das classes.\")\n",
    "#     class_names = sorted(list(set(y_test_true_fraud_labels)))\n",
    "\n",
    "\n",
    "# # 2. Calcular a Matriz de Confus√£o\n",
    "# cm = confusion_matrix(\n",
    "#     y_test_true_fraud_labels, \n",
    "#     y_pred_multiclass_labels, \n",
    "#     labels=class_names\n",
    "# )\n",
    "# cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "\n",
    "\n",
    "# # 3. Plotar a Matriz de Confus√£o\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(\n",
    "#     cm_df,\n",
    "#     annot=True,        # Mostra os n√∫meros dentro das c√©lulas\n",
    "#     fmt='d',           # Formato decimal (inteiro)\n",
    "#     cmap='Blues',      # Esquema de cores (pode ser 'YlGnBu' ou 'Reds')\n",
    "#     cbar=True          # Mostra a barra de cores\n",
    "# )\n",
    "\n",
    "# plt.title('Matriz de Confus√£o Multiclasse (Tipos de Fraude)', fontsize=14)\n",
    "# plt.ylabel('Classe Verdadeira', fontsize=12)\n",
    "# plt.xlabel('Classe Prevista', fontsize=12)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\nMatriz de Confus√£o Visualizada gerada. Analise as c√©lulas fora da diagonal principal (erros).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "348e9dbd-9e31-4230-8452-7094204da054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### An√°lise Multiclasse: An√°lise de Erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8acd4cb-94c4-43fc-a3f5-dd9b83509511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- An√°lise de Erros (Modelo Multiclasse) ---\")\n",
    "\n",
    "try:\n",
    "    # Unir os dados de teste de fraude com as previs√µes\n",
    "    df_erros_multi = X_test_fraud.copy()\n",
    "    df_erros_multi['real'] = y_test_multiclass_encoded\n",
    "    df_erros_multi['previsto'] = y_pred_multiclass_encoded\n",
    "\n",
    "    # Filtrar apenas as previs√µes incorretas\n",
    "    df_erros_multi = df_erros_multi[df_erros_multi['real'] != df_erros_multi['previsto']]\n",
    "\n",
    "    # Mapear os IDs de volta para os nomes das classes para facilitar a leitura\n",
    "    df_erros_multi['real_label'] = df_erros_multi['real'].map(lambda x: label_encoder.inverse_transform([x])[0])\n",
    "    df_erros_multi['previsto_label'] = df_erros_multi['previsto'].map(lambda x: label_encoder.inverse_transform([x])[0])\n",
    "    \n",
    "    print(f\"Total de erros de classifica√ß√£o no teste: {len(df_erros_multi)}\")\n",
    "\n",
    "    if not df_erros_multi.empty:\n",
    "        # Mostrar os tipos de erro mais comuns\n",
    "        print(\"\\nTipos de erro mais comuns (Real -> Previsto):\")\n",
    "        print(df_erros_multi.groupby(['real_label', 'previsto_label']).size().sort_values(ascending=False))\n",
    "        \n",
    "        # Mostrar descri√ß√£o estat√≠stica das transa√ß√µes erradas\n",
    "        print(\"\\nDescri√ß√£o das transa√ß√µes classificadas incorretamente:\")\n",
    "        print(df_erros_multi[numeric_features_eda].describe())\n",
    "    else:\n",
    "        print(\"\\nO modelo multiclasse acertou todas as previs√µes no set de teste!\")\n",
    "\n",
    "except NameError as e:\n",
    "    print(f\"Erro: Vari√°vel n√£o encontrada. {e}\")\n",
    "    print(\"Certifique-se de que a C√©lula 22 foi executada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74a0494-24f1-4201-89e6-f137b37330b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e31568d-5eab-4dcd-b1fc-102da8a3cee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Avalia√ß√£o Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b6b843-4dc9-4648-bca0-7f1e1cbd8d6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Iniciando Avalia√ß√£o Final (P√≥s-Treino) com Artefatos Salvos ---\")\n",
    "\n",
    "# 1. Carregar artefatos do Volume\n",
    "try:\n",
    "    loaded_pipeline_binary = joblib.load(os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_binary_pipeline.pkl\"))\n",
    "    loaded_pipeline_multiclass = joblib.load(os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_pipeline.pkl\"))\n",
    "    \n",
    "    map_path = os.path.join(MODEL_ARTIFACTS_DIR, \"fraud_type_label_map.json\")\n",
    "    with open(map_path, 'r') as f:\n",
    "        # Converter chaves JSON (string) de volta para inteiros\n",
    "        loaded_label_map_str = json.load(f)\n",
    "        loaded_label_map = {int(k): v for k, v in loaded_label_map_str.items()}\n",
    "        \n",
    "    print(\"Artefatos (2 pipelines, 1 mapa) carregados com sucesso do Volume.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro fatal ao carregar artefatos do Volume: {e}\")\n",
    "    # Se falhar aqui, n√£o podemos continuar\n",
    "    raise e\n",
    "\n",
    "# --- Avalia√ß√£o Modelo 1: Classifica√ß√£o Bin√°ria ---\n",
    "print(\"\\n--- Avalia√ß√£o Modelo 1: Classifica√ß√£o Bin√°ria (em X_test) ---\")\n",
    "\n",
    "# Usar os dados de teste reais (y_test_binary)\n",
    "y_pred_binary_loaded = loaded_pipeline_binary.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test_binary, y_pred_binary_loaded, target_names=['Legitimo', 'Fraude']))\n",
    "print(\"Matriz de Confus√£o (Bin√°rio):\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_loaded))\n",
    "\n",
    "\n",
    "# --- Avalia√ß√£o Modelo 2: Classifica√ß√£o Multiclasse ---\n",
    "print(\"\\n--- Avalia√ß√£o Modelo 2: Classifica√ß√£o Multiclasse (em X_test ONDE y_test==1) ---\")\n",
    "\n",
    "# Filtrar o X_test para incluir apenas as fraudes VERDADEIRAS\n",
    "# (para avaliar o qu√£o bem o 2¬∫ modelo classifica os tipos de fraude reais)\n",
    "X_test_true_fraud = X_test[y_test_binary == 1]\n",
    "\n",
    "# --- CORRE√á√ÉO AQUI ---\n",
    "# Usamos 'y_test_multiclass' (o split de teste)\n",
    "# Em vez de 'y_multiclass' (o dataset completo)\n",
    "y_test_true_fraud_labels = y_test_multiclass[y_test_binary == 1]\n",
    "# --- FIM DA CORRE√á√ÉO ---\n",
    "\n",
    "\n",
    "if not X_test_true_fraud.empty:\n",
    "    # Prever os √≠ndices (0, 1, 2)\n",
    "    y_pred_multiclass_idx = loaded_pipeline_multiclass.predict(X_test_true_fraud)\n",
    "    \n",
    "    # Mapear os √≠ndices de volta para os labels string ('scam', 'roubo')\n",
    "    y_pred_multiclass_labels = [loaded_label_map.get(idx, 'unknown') for idx in y_pred_multiclass_idx]\n",
    "    \n",
    "    # Classes reais para o relat√≥rio\n",
    "    true_labels_list = list(loaded_label_map.values())\n",
    "    \n",
    "    print(classification_report(y_test_true_fraud_labels, y_pred_multiclass_labels, labels=true_labels_list))\n",
    "    print(\"Matriz de Confus√£o (Multiclasse):\")\n",
    "    print(confusion_matrix(y_test_true_fraud_labels, y_pred_multiclass_labels, labels=true_labels_list))\n",
    "else:\n",
    "    print(\"N√£o foram encontradas fraudes verdadeiras no conjunto de teste para avaliar o modelo multiclasse.\")\n",
    "\n",
    "print(\"\\nC√©lula 8 conclu√≠da. Avalia√ß√£o final completa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3de6a438-7f30-449f-af22-0cc6046ac5a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Treinamento",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
