{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "892a9927-712c-430a-a438-9c50588fde5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade scikit-learn==1.4.2 tensorflow==2.16.1 scikeras==0.13.0 joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8bd723d-0015-4a1a-a5f3-eed4664a619d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40baa35b-83fb-4241-9214-5358136278a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Altere esta linha para o caminho que você criou no Passo 3\n",
    "MODEL_DIR = \"/Volumes/transacoes_db/copper/files/pix_fraud/production_artifacts/\" \n",
    "\n",
    "print(f\"Verificando o diretório local: {os.path.abspath(MODEL_DIR)}\")\n",
    "\n",
    "try:\n",
    "    files = os.listdir(MODEL_DIR)\n",
    "    if not files:\n",
    "        print(\"Pasta vazia. Você colocou os ficheiros .pkl aqui?\")\n",
    "    else:\n",
    "        print(\"Ficheiros encontrados:\")\n",
    "        for f in files:\n",
    "            print(f\"- {f}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: A pasta '{MODEL_DIR}' não foi encontrada. Verifique o caminho.\")\n",
    "except NotADirectoryError:\n",
    "    print(f\"ERRO: O caminho '{MODEL_DIR}' não é um diretório/pasta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8233f3b-0f50-4fc1-b41b-a44b41f7f2cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from mlflow.models.signature import infer_signature\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Constantes de Produção ---\n",
    "# Este deve ser o mesmo diretório do Volume usado no treinamento\n",
    "MODEL_DIR = \"/Volumes/transacoes_db/copper/files/pix_fraud/production_artifacts/\"\n",
    "BINARY_THRESHOLD = 0.5 # Threshold de decisão para fraude binária\n",
    "\n",
    "# Suprimir warnings de serialização/versão que podem ocorrer\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Suprimir logs do TensorFlow\n",
    "\n",
    "# --- Definição da Função de Engenharia de Features ---\n",
    "# (Necessário para carregar o pipeline)\n",
    "\n",
    "def feature_engineer_datetimes(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Recebe um DataFrame com as colunas de data/hora e retorna\n",
    "    um DataFrame com features numéricas de engenharia.\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "    df_out = pd.DataFrame(index=df.index)\n",
    "    now = datetime.now()\n",
    "    dt_tx = pd.to_datetime(df['data_transacao'])\n",
    "    df_out['tx_hora_do_dia'] = dt_tx.dt.hour\n",
    "    df_out['tx_dia_da_semana'] = dt_tx.dt.dayofweek\n",
    "    df_out['tx_mes'] = dt_tx.dt.month\n",
    "    \n",
    "    # <--- Esta linha está comentada para corresponder ao pipeline treinado\n",
    "    # df_out['pagador_idade_conta_dias'] = (now - pd.to_datetime(df['pagador_conta_aberta_em'])).dt.days\n",
    "    \n",
    "    df_out['recebedor_idade_conta_dias'] = (now - pd.to_datetime(df['recebedor_conta_aberta_em'])).dt.days\n",
    "    df_out['pagador_idade_anos'] = ((now - pd.to_datetime(df['pagador_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "    df_out['recebedor_idade_anos'] = ((now - pd.to_datetime(df['recebedor_data_nascimento'])).dt.days / 365.25).astype(int)\n",
    "    df_out = df_out.fillna(0)\n",
    "    return df_out\n",
    "\n",
    "\n",
    "# --- Definições das Funções de Construção de Modelo ---\n",
    "# (Necessário para carregar os KerasClassifiers)\n",
    "\n",
    "def build_binary_model(meta):\n",
    "    \"\"\"Constrói o modelo binário para o KerasClassifier.\"\"\"\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    tf.random.set_seed(42) \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['AUC', tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_multiclass_model(meta):\n",
    "    \"\"\"Constrói o modelo multiclasse para o KerasClassifier.\"\"\"\n",
    "    n_features_in = meta[\"n_features_in_\"]\n",
    "    n_classes_out = meta[\"n_classes_\"]\n",
    "    tf.random.set_seed(42)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=(n_features_in,)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dense(n_classes_out, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Carregamento de Artefatos ---\n",
    "\n",
    "# <--- MODIFICADO: Os nomes dos ficheiros foram corrigidos aqui ---\n",
    "def carregar_artefatos(model_dir: str):\n",
    "    \"\"\"\n",
    "    Carrega todos os artefatos necessários (pipelines e mapa de labels)\n",
    "    do diretório especificado (no Volume).\n",
    "    \"\"\"\n",
    "    print(f\"Carregando artefatos de: {model_dir}\")\n",
    "    try:\n",
    "        # Nomes atualizados para corresponder aos ficheiros reais na pasta\n",
    "        pipeline_binario = joblib.load(os.path.join(model_dir, \"fraud_binary_pipeline.pkl\"))\n",
    "        pipeline_multiclass = joblib.load(os.path.join(model_dir, \"fraud_type_pipeline.pkl\"))\n",
    "        label_map_path = os.path.join(model_dir, \"fraud_type_label_map.json\")\n",
    "            \n",
    "        with open(label_map_path, 'r') as f:\n",
    "            label_map_str_keys = json.load(f)\n",
    "            # Converter chaves do JSON (string) de volta para inteiros\n",
    "            label_map = {int(k): v for k, v in label_map_str_keys.items()}\n",
    "            \n",
    "        print(\"Artefatos (2 pipelines, 1 mapa de labels) carregados com sucesso.\")\n",
    "        return pipeline_binario, pipeline_multiclass, label_map\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro crítico: Arquivo de modelo/mapa não encontrado. Verifique os nomes dos arquivos. {e}\")\n",
    "        return None, None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado ao carregar artefatos: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# --- Função de Predição em Cascata (COM CORREÇÃO) ---\n",
    "\n",
    "def prever_fraude(df_novo: pd.DataFrame, pipeline_binario, pipeline_multiclass, label_map) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executa a predição em cascata para novas transações.\n",
    "    Recebe um DataFrame Pandas com o schema exato da view de features.\n",
    "    \"\"\"\n",
    "    if pipeline_binario is None or pipeline_multiclass is None or label_map is None:\n",
    "        raise ValueError(\"Modelos ou mapa de labels não foram carregados corretamente.\")\n",
    "\n",
    "    if not isinstance(df_novo, pd.DataFrame):\n",
    "        df_novo = pd.DataFrame([df_novo])\n",
    "        \n",
    "    df_results = df_novo.copy()\n",
    "\n",
    "    # 1. Modelo Binário\n",
    "    try:\n",
    "        fraud_probabilities = pipeline_binario.predict_proba(df_novo)[:, 1]\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na predição binária: {e}\")\n",
    "        df_results['predicted_fraud'] = np.nan\n",
    "        df_results['fraud_probability'] = np.nan\n",
    "        df_results['predicted_fraud_type'] = None\n",
    "        df_results['predicted_type_probability'] = np.nan\n",
    "        df_results['type_probabilities'] = None\n",
    "        df_results['resumo_da_predicao'] = \"Erro na predição\" \n",
    "        return df_results\n",
    "\n",
    "    df_results['fraud_probability'] = fraud_probabilities\n",
    "    df_results['predicted_fraud'] = (fraud_probabilities >= BINARY_THRESHOLD).astype(int)\n",
    "\n",
    "    # Inicializar colunas\n",
    "    df_results['predicted_fraud_type'] = None\n",
    "    df_results['predicted_type_probability'] = np.nan\n",
    "    df_results['type_probabilities'] = [{} for _ in range(len(df_results))]\n",
    "\n",
    "    # 2. Modelo Multiclasse (só para fraudes)\n",
    "    indices_fraude = df_results[df_results['predicted_fraud'] == 1].index\n",
    "\n",
    "    if not indices_fraude.empty:\n",
    "        df_fraude = df_results.loc[indices_fraude]\n",
    "        \n",
    "        try:\n",
    "            type_probs_matrix = pipeline_multiclass.predict_proba(df_fraude)\n",
    "\n",
    "            # --- INÍCIO DA CORREÇÃO ---\n",
    "            # O 'predict_proba' para uma única amostra retorna um array 1D (ex: [0.1, 0.8, 0.1]).\n",
    "            # As funções np.argmax(axis=1) e np.max(axis=1) exigem um array 2D.\n",
    "            # Esta verificação garante que 'type_probs_matrix' seja sempre 2D.\n",
    "            if type_probs_matrix.ndim == 1:\n",
    "                # Transforma [0.1, 0.8, 0.1] em [[0.1, 0.8, 0.1]]\n",
    "                type_probs_matrix = np.array([type_probs_matrix])\n",
    "            # --- FIM DA CORREÇÃO ---\n",
    "\n",
    "            # Agora estas linhas funcionarão com 1 ou N amostras\n",
    "            type_predictions_indices = np.argmax(type_probs_matrix, axis=1)\n",
    "            predicted_type_probs = np.max(type_probs_matrix, axis=1)\n",
    "            predicted_types = [label_map.get(idx, 'unknown') for idx in type_predictions_indices]\n",
    "            \n",
    "            df_results.loc[indices_fraude, 'predicted_fraud_type'] = predicted_types\n",
    "            df_results.loc[indices_fraude, 'predicted_type_probability'] = predicted_type_probs\n",
    "            \n",
    "            type_probs_list = []\n",
    "            for probs_row in type_probs_matrix:\n",
    "                row_dict = {label_map.get(i, 'unknown'): float(prob) for i, prob in enumerate(probs_row)}\n",
    "                type_probs_list.append(row_dict)\n",
    "            \n",
    "            df_results.loc[indices_fraude, 'type_probabilities'] = pd.Series(\n",
    "                type_probs_list, \n",
    "                index=indices_fraude, \n",
    "                dtype='object'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na predição multiclasse: {e}\")\n",
    "            # Se falhar, o tipo de fraude ficará como 'None'\n",
    "\n",
    "    # --- LÓGICA DA STRING DE SAÍDA ---\n",
    "    \n",
    "    # 1. Definir o padrão (Não é fraude)\n",
    "    df_results['resumo_da_predicao'] = \"Não é uma fraude.\"\n",
    "    \n",
    "    # 2. Atualizar apenas as linhas que SÃO fraude (usando os índices)\n",
    "    if not indices_fraude.empty:\n",
    "        tipos_de_fraude = df_results.loc[indices_fraude, 'predicted_fraud_type']\n",
    "        df_results.loc[indices_fraude, 'resumo_da_predicao'] = \"É UMA FRAUDE do tipo \" + tipos_de_fraude.astype(str)\n",
    "        df_results['resumo_da_predicao'] = df_results['resumo_da_predicao'].str.replace(\"do tipo None\", \"do tipo desconhecido\")\n",
    "\n",
    "    return df_results\n",
    "\n",
    "# --- Exemplo de Uso (Simulação) ---\n",
    "print(\"\\n--- SIMULANDO EXECUÇÃO DE INFERÊNCIA AUTÔNOMA ---\")\n",
    "\n",
    "# 1. Carregar os artefatos UMA VEZ\n",
    "p_bin, p_multi, l_map = carregar_artefatos(MODEL_DIR)\n",
    "\n",
    "print(\"\\n--- CÉLULA 10: TESTANDO PAYLOAD DE ATAQUE REALISTA ---\")\n",
    "\n",
    "if 'p_bin' in locals() and p_bin:\n",
    "    \n",
    "    # Payload 1 atualizado com as 7 novas features\n",
    "    transacao_legitima = {\n",
    "        'valor_transacao': 50.20,\n",
    "        'data_transacao': datetime.now(),\n",
    "        'tipo_iniciacao_pix_id': 1, 'finalidade_pix_id': 1,\n",
    "        'pagador_saldo': 1500.00, 'pagador_conta_aberta_em': '2018-05-10T10:00:00',\n",
    "        'pagador_tipo_conta_id': 1, 'pagador_natureza_id': 1, 'pagador_data_nascimento': '1985-01-15T00:00:00',\n",
    "        'recebedor_saldo': 3000.00, 'recebedor_conta_aberta_em': '2019-11-20T14:30:00',\n",
    "        'recebedor_tipo_conta_id': 1, 'recebedor_natureza_id': 1, 'recebedor_data_nascimento': '1990-03-22T00:00:00',\n",
    "        'pagador_txs_ultimas_24h': 2, 'pagador_valor_ultimas_24h': 100.0,\n",
    "        'recebedor_txs_ultima_1h': 0, 'recebedor_valor_ultima_1h': 0.0,\n",
    "        'pagador_segundos_desde_ultima_tx': 86400,\n",
    "        # --- Novas Features (Valores legítimos) ---\n",
    "        'primeira_interacao': 0,\n",
    "        'pagador_interacoes_com_recebedor': 5,\n",
    "        'recebedor_num_pagadores_unicos_24h': 10,\n",
    "        'recebedor_idade_conta_dias': 1500,\n",
    "        'pagador_idade_conta_dias': 2000,\n",
    "        'valor_vs_media_pagador_30d': 0.8,\n",
    "        'valor_vs_saldo_pagador': 0.03 # (50.20 / 1500.00)\n",
    "    }\n",
    "\n",
    "    # Payload 2 atualizado com as 7 novas features\n",
    "    transacao_ataque_fan_in = {\n",
    "        'valor_transacao': 30.00, \n",
    "        'data_transacao': datetime.now().replace(hour=3, minute=30), # Madrugada\n",
    "        'tipo_iniciacao_pix_id': 2, 'finalidade_pix_id': 2,\n",
    "        'pagador_saldo': 10.00, # Saldo baixo\n",
    "        'pagador_conta_aberta_em': datetime.now().replace(day=1), # Conta Nova\n",
    "        'pagador_tipo_conta_id': 1, 'pagador_natureza_id': 1, 'pagador_data_nascimento': '1998-07-10T00:00:00',\n",
    "        'recebedor_saldo': 50000.00, \n",
    "        'recebedor_conta_aberta_em': datetime.now().replace(day=2), # Conta Nova\n",
    "        'recebedor_tipo_conta_id': 2, 'recebedor_natureza_id': 2, 'recebedor_data_nascimento': '1999-12-01T00:00:00',\n",
    "        'pagador_txs_ultimas_24h': 1, \n",
    "        'pagador_valor_ultimas_24h': 0.0,\n",
    "        'recebedor_txs_ultima_1h': 50, # SINAL: 50 txs na última hora\n",
    "        'recebedor_valor_ultima_1h': 50000.00, # SINAL: R$ 50k recebidos\n",
    "        'pagador_segundos_desde_ultima_tx': 1,\n",
    "        # --- Novas Features (Valores de ataque) ---\n",
    "        'primeira_interacao': 1, # SINAL\n",
    "        'pagador_interacoes_com_recebedor': 0, # SINAL\n",
    "        'recebedor_num_pagadores_unicos_24h': 120, # SINAL\n",
    "        'recebedor_idade_conta_dias': 1, # SINAL\n",
    "        'pagador_idade_conta_dias': 2, # SINAL\n",
    "        'valor_vs_media_pagador_30d': None, # SINAL (Imputer vai tratar)\n",
    "        'valor_vs_saldo_pagador': 3.0 # SINAL (30.00 / 10.00)\n",
    "    }\n",
    "    \n",
    "    payload_realista = pd.DataFrame([transacao_legitima, transacao_ataque_fan_in])\n",
    "    \n",
    "    print(\"Executando predição no payload de ataque realista...\")\n",
    "    \n",
    "    resultados_realistas = prever_fraude(payload_realista, p_bin, p_multi, l_map)\n",
    "    \n",
    "    print(\"\\nResultados da Predição Realista (Saída):\")\n",
    "    output_columns = ['resumo_da_predicao', 'fraud_probability', 'predicted_type_probability']\n",
    "    print(resultados_realistas[output_columns])\n",
    "\n",
    "else:\n",
    "    print(\"Erro: Modelos não foram carregados. Execute o carregamento primeiro.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Testes e Aplicacoes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
